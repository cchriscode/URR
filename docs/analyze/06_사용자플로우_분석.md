# URR 사용자 플로우 및 시스템 아키텍처 분석

---

## 1. 시스템 아키텍처 개요

### 1-1. Two-Tier 큐 설계 근거

URR 시스템은 티켓 예매 시 발생하는 대규모 동시 접속을 처리하기 위해 **Two-Tier 대기열** 구조를 채택한다. 각 Tier는 서로 다른 기술 스택으로 구현되어 있으며, 역할이 명확히 분리되어 있다.

**Tier 1 (VWR - Virtual Waiting Room): 서버리스 구조**

- **구성**: API Gateway + Lambda + DynamoDB
- **역할**: CDN 레벨에서 대규모 동시 접속을 수용하는 유량 제어
- **핵심 파일**:
  - `lambda/vwr-api/index.js` (1-63행): Lambda 핸들러 - 단일 Lambda가 assign/check/status 세 엔드포인트를 처리하여 cold start 최소화
  - `lambda/vwr-api/handlers/assign.js` (10-52행): 대기 위치 할당 - DynamoDB의 atomic counter로 순서 보장
  - `lambda/vwr-api/lib/dynamo.js` (16-47행): `nextPosition` 원자적 증가 + `ConditionExpression`으로 VWR 활성 상태 검증
  - `lambda/vwr-counter-advancer/index.js` (22-60행): EventBridge 1분 주기로 호출되며, 내부적으로 6개 사이클(10초 간격)을 돌려 10초 단위 입장 제어 달성
  - `lambda/edge-queue-check/index.js` (70-129행): Lambda@Edge viewer-request에서 Tier 1/Tier 2 토큰을 검증하여 무단 접근 차단
  - `apps/vwr/index.html` (149-329행): S3에 호스팅되는 정적 대기 페이지 - CloudFront CDN 캐싱으로 서버 부하 없이 무한 사용자 수용

**Tier 2 (Queue): Pod 기반 구조**

- **구성**: queue-service (Spring Boot) + Redis
- **역할**: 인증된 사용자에 대한 정밀한 순서 관리 및 동시 접속 수 제한
- **핵심 파일**:
  - `services-spring/queue-service/src/main/java/guru/urr/queueservice/service/QueueService.java` (22-391행): Redis Sorted Set 기반 큐 관리
  - `services-spring/queue-service/src/main/java/guru/urr/queueservice/service/AdmissionWorkerService.java` (47-48행): 1초 간격 스케줄링으로 배치 입장 처리
  - `services-spring/queue-service/src/main/java/guru/urr/queueservice/config/RedisConfig.java` (14-17행): Lua 스크립트를 통한 원자적 입장 제어

**설계 선택의 이유**:

1. **VWR(Tier 1)이 서버리스인 이유**: 티켓 오픈 순간 수십만 명이 동시에 접속할 때, Lambda는 자동으로 동시 실행 인스턴스를 늘려 대응한다. DynamoDB는 on-demand 모드에서 무한 확장이 가능하며, 정적 대기 페이지는 CloudFront에서 캐싱되어 origin 서버에 부하를 주지 않는다.

2. **Queue(Tier 2)가 Pod 기반인 이유**: 인증된 사용자의 정밀한 순서 관리, 활성 사용자 수 제한(threshold), 하트비트 기반 이탈 감지 등은 Redis의 실시간 데이터 구조(Sorted Set, Set)와 Lua 스크립트 원자성이 필요하다. 이는 DynamoDB보다 Redis가 적합한 영역이다.

3. **분리의 이점**: Tier 1이 대규모 동시 접속의 충격을 흡수한 후, Tier 2로 제어된 수의 사용자만 유입되므로 EKS 클러스터의 Pod 수를 예측 가능한 범위로 유지할 수 있다.

### 1-2. 전체 서비스 구성

Gateway 서비스가 모든 API 요청을 라우팅한다.

- `services-spring/gateway-service/src/main/resources/application.yml` (11-75행): 라우팅 규칙 정의

| 서비스 | 라우팅 경로 | 역할 |
|--------|-------------|------|
| auth-service | `/api/v1/auth/**` | 인증/인가 |
| catalog-service | `/api/v1/events/**`, `/api/v1/admin/**`, `/api/v1/artists/**` | 이벤트/아티스트 카탈로그 |
| ticket-service | `/api/v1/tickets/**`, `/api/v1/seats/**`, `/api/v1/reservations/**`, `/api/v1/transfers/**`, `/api/v1/memberships/**` | 좌석/예매/양도/멤버십 |
| payment-service | `/api/v1/payments/**` | 결제 |
| queue-service | `/api/v1/queue/**` | Tier 2 대기열 |
| stats-service | `/api/v1/stats/**` | 통계 |
| community-service | `/api/v1/community/**`, `/api/v1/news/**` | 커뮤니티 |

---

## 2. 사용자 플로우 상세

### 2-1. 회원가입 & 로그인

#### Google OAuth 플로우

1. **프론트엔드에서 Google 로그인 버튼 클릭**
   - `apps/web/src/lib/api-client.ts` (140행): `authApi.google(credential)` 호출
   - Google Identity Services SDK가 `credential` (ID Token)을 반환

2. **auth-service로 credential 전달**
   - `services-spring/auth-service/src/main/java/guru/urr/authservice/controller/AuthController.java` (85-101행): `POST /api/auth/google` 엔드포인트
   - `AuthController.google()` 메서드가 credential을 `AuthService.googleLogin()`에 전달

3. **Google ID Token 검증**
   - `services-spring/auth-service/src/main/java/guru/urr/authservice/service/AuthService.java` (197-259행): `googleLogin()` 메서드
   - 206-211행: `GoogleIdTokenVerifier.verify(credential)` 호출하여 Google 서버와 토큰 검증
   - 217-225행: payload에서 googleId, email, name, picture 추출
   - 227-238행: 이메일로 기존 사용자 조회, 없으면 새 사용자 생성 (`UserEntity`)

4. **JWT 토큰 발급**
   - `services-spring/auth-service/src/main/java/guru/urr/authservice/security/JwtService.java` (31-46행): `generateToken()` - access token (HS256, userId/email/role 클레임 포함)
   - `JwtService.java` (52-67행): `generateRefreshToken()` - refresh token (familyId 포함, 토큰 재사용 감지를 위한 family 기반 rotation)

5. **쿠키 설정**
   - `services-spring/auth-service/src/main/java/guru/urr/authservice/util/CookieHelper.java` (28-34행): `addAccessTokenCookie()` - HttpOnly, Secure, SameSite=Lax, path=/
   - `CookieHelper.java` (38-44행): `addRefreshTokenCookie()` - path=/api/auth로 제한하여 refresh 요청에만 쿠키 전송
   - `AuthController.java` (94-99행): response에 access_token, refresh_token 쿠키 추가

6. **프론트엔드 인증 상태 관리**
   - `apps/web/src/lib/auth-context.tsx` (23-79행): `AuthProvider` 컴포넌트
   - 27-51행: `fetchUser()` 콜백 - `/api/v1/auth/me` 호출하여 사용자 정보 로드
   - 53-55행: 마운트 시 자동으로 `fetchUser()` 실행
   - `apps/web/src/lib/api-client.ts` (79-131행): 401 응답 시 자동 token refresh (interceptor)
   - 102-106행: `POST /auth/refresh` 호출 - 쿠키의 refresh_token으로 새 access_token 획득

#### 일반 로그인 플로우

- `AuthController.java` (48-55행): `POST /api/auth/login` 엔드포인트
- `AuthService.java` (87-111행): 이메일/패스워드 검증 후 JWT 발급
- `apps/web/src/app/login/page.tsx`: 로그인 폼 컴포넌트

#### 회원가입 플로우

- `AuthController.java` (39-46행): `POST /api/auth/register` 엔드포인트
- `AuthService.java` (66-84행): 이메일 중복 확인 후 BCrypt 해시 저장, JWT 발급

### 2-2. 이벤트 탐색

1. **랜딩 페이지 접속**
   - `apps/web/src/app/page.tsx`: 서버 컴포넌트에서 이벤트 목록 SSR 렌더링
   - `apps/web/src/app/page-client.tsx`: 클라이언트 측 이벤트 목록 인터랙션

2. **이벤트 목록 API 호출**
   - `apps/web/src/lib/api-client.ts` (143-146행): `eventsApi.list(params)` - `GET /api/v1/events`
   - `apps/web/src/hooks/use-events.ts`: React Query 기반 이벤트 데이터 fetching hook

3. **catalog-service 처리**
   - `services-spring/catalog-service/src/main/java/guru/urr/catalogservice/domain/event/controller/EventController.java` (22-29행): `GET /api/events` 엔드포인트 - status, q(검색어), page, limit 파라미터 지원
   - `services-spring/catalog-service/src/main/java/guru/urr/catalogservice/domain/event/service/EventReadService.java` (26-93행): `listEvents()` 메서드
   - 29-39행: SQL - events + ticket_types LEFT JOIN으로 min_price, max_price 집계
   - 44-53행: 상태 필터링 + ILIKE 검색 (title, artist_name, venue, address)
   - 59행: `sale_start_date ASC` 정렬, LIMIT/OFFSET 페이지네이션
   - 80-88행: 총 건수 별도 쿼리 → totalPages 계산

4. **페이지네이션 구조**
   - `EventReadService.java` (83-88행): 응답에 `page`, `limit`, `total`, `totalPages` 포함

### 2-3. 이벤트 상세 조회

1. **이벤트 상세 페이지 접속**
   - `apps/web/src/app/events/[id]/page.tsx`: 서버 컴포넌트 (SSR)
   - `apps/web/src/app/events/[id]/page-client.tsx` (14-36행): 클라이언트 컴포넌트 - `useEventDetail(id)` hook으로 데이터 fetching
   - `apps/web/src/lib/api-client.ts` (145행): `eventsApi.detail(id)` - `GET /api/v1/events/{id}`

2. **catalog-service 상세 조회**
   - `EventController.java` (32-35행): `GET /api/events/{id}`
   - `EventReadService.java` (95-120행): `getEventDetail()` 메서드
   - 96-98행: events 테이블에서 이벤트 정보 조회
   - 101행: `ticketInternalClient.getTicketTypesByEvent(eventId)` - ticket-service 내부 API 호출로 티켓 종류 조회
   - 109-117행: artist_id가 있으면 `PreSaleSchedule.compute()` 호출하여 선예매 일정 계산

3. **좌석 배치도 로딩**
   - `EventReadService.java` (140-173행): `getSeatsByEvent()` 메서드
   - 141-146행: events + seat_layouts JOIN으로 layout_config 조회
   - 157-162행: seats 테이블에서 해당 이벤트의 전체 좌석 목록 조회 (section, row_number, seat_number 순)

4. **"예매하기" 버튼 클릭 플로우**
   - `apps/web/src/app/events/[id]/event-detail-client.tsx` (141-158행):
   - 51-54행: `canBook` 조건 - status가 "on_sale"이거나 "upcoming"이면서 카운트다운이 만료된 경우
   - 143-148행: `onClick={() => setVwrOpen(true)}` - VWR 모달 열기
   - 149-157행: `VwrModal` 컴포넌트 렌더링, `onAdmitted` 콜백에서 `/queue/{eventId}`로 이동

### 2-4. VWR 대기 (Tier 1)

#### Step 1: 사용자가 "예매하기" 클릭 → VWR 모달 열림

- `apps/web/src/app/events/[id]/event-detail-client.tsx` (143행): `setVwrOpen(true)` 호출
- `apps/web/src/components/vwr-modal.tsx` (20-121행): `VwrModal` 컴포넌트 렌더링
- `vwr-modal.tsx` (21-22행): `useVwrPolling(eventId, open, onAdmitted)` hook 시작

#### Step 2: 프론트엔드가 VWR 상태 확인 API 호출

- `apps/web/src/hooks/use-vwr-polling.ts` (181-194행): `init()` 함수
- 183-184행: `vwrApi.status(eventId)` 호출 → `GET /vwr-api/vwr/status/{eventId}`
- `apps/web/src/lib/api-client.ts` (255-259행): `vwrApi.status()` - fetch API로 CloudFront를 거쳐 API Gateway Lambda로 요청
- CloudFront Function이 `/vwr-api` prefix를 제거 후 API Gateway로 전달:
  - `terraform/modules/cloudfront/main.tf` (422-437행): `vwr_api_rewrite` CloudFront Function
- `lambda/vwr-api/index.js` (44-45행): `resource === '/vwr/status/{eventId}'` 매칭
- `lambda/vwr-api/handlers/status.js` (9-31행): DynamoDB counters 테이블 조회
- `lambda/vwr-api/lib/dynamo.js` (75-89행): `getEventStatus()` - isActive, nextPosition, servingCounter 반환

#### Step 3: VWR 활성 시 - 대기 위치 할당

- `use-vwr-polling.ts` (187-188행): `status.isActive === false`이면 `handleAdmitted()` 호출하여 바이패스
- `use-vwr-polling.ts` (210행): VWR 활성이면 `startAssign()` 호출
- `use-vwr-polling.ts` (141-179행): `startAssign()` 함수
- 145행: `vwrApi.assign(eventId, userId)` 호출 → `POST /vwr-api/vwr/assign/{eventId}`
- `apps/web/src/lib/api-client.ts` (260-268행): `vwrApi.assign()` - body에 userId 포함
- `lambda/vwr-api/handlers/assign.js` (10-52행): `handler(eventId, body)`
- 14-19행: `getEventStatus()`로 VWR 활성 확인, 비활성이면 404 반환
- 23행: `crypto.randomUUID()`로 requestId 생성
- 26행: `assignPosition(eventId, requestId, userId)` 호출
- `lambda/vwr-api/lib/dynamo.js` (16-47행): `assignPosition()`
  - 18-29행: DynamoDB `UpdateCommand`로 `nextPosition` 원자적 증가 (`ADD nextPosition :one`)
  - 22행: `ConditionExpression: 'isActive = :true'` - VWR 활성 상태에서만 동작
  - 34-44행: positions 테이블에 `PutCommand`로 (eventId, requestId, position, userId, TTL 24시간) 저장
- 응답: `{ requestId, position, estimatedWait, servingCounter }`

#### Step 4: 프론트엔드가 check 엔드포인트 폴링

- `use-vwr-polling.ts` (164행): `setTimeout(pollCheck, DEFAULT_POLL_SECONDS * 1000)` - 5초 간격 시작
- `use-vwr-polling.ts` (102-138행): `pollCheck()` 함수
- 107행: `vwrApi.check(eventId, reqId, userId)` → `GET /vwr-api/vwr/check/{eventId}/{requestId}?userId=...`
- `apps/web/src/lib/api-client.ts` (269-273행): `vwrApi.check()` - fetch API
- `lambda/vwr-api/handlers/check.js` (11-57행): `handler(eventId, requestId, queryParams)`
  - 12-13행: `getPositionAndCounter()` - DynamoDB에서 position과 servingCounter 병렬 조회
  - `lambda/vwr-api/lib/dynamo.js` (52-70행): Promise.all로 positions/counters 테이블 동시 조회

#### Step 5: Lambda가 position <= servingCounter인지 확인

- `lambda/vwr-api/handlers/check.js` (31행): `const admitted = position <= servingCounter`
- `check.js` (44-51행): 미입장 시 남은 거리에 따른 동적 폴링 간격 설정
  - 500명 이내: 2초, 2000명 이내: 5초, 10000명 이내: 10초, 그 이상: 15초

**servingCounter 전진 메커니즘**:
- `lambda/vwr-counter-advancer/index.js` (22-60행): EventBridge → Lambda (1분 간격 호출)
- 15-16행: `CYCLES_PER_INVOCATION = 6`, `CYCLE_INTERVAL_MS = 10000` - 10초마다 6번 실행
- 63-90행: `advanceCounter()` - `ADD servingCounter :batch` (기본 500명씩)
- 69행: `ConditionExpression`으로 servingCounter가 nextPosition을 초과하지 않도록 보장

#### Step 6: 입장 허용 시 - VWR 토큰 발급

- `lambda/vwr-api/handlers/check.js` (41-42행): `admitted === true`일 때 `createToken(eventId, userId)` 호출
- `lambda/vwr-api/lib/token.js` (11-27행): `createToken()` - 경량 JWT 구현 (외부 라이브러리 없음, cold start 최적화)
  - 14-20행: payload에 `{ sub: eventId, uid: userId, tier: 1, iat, exp: now + 600 }` (10분 유효)
  - 24-26행: HMAC-SHA256 서명
- `use-vwr-polling.ts` (110-113행): `data.admitted && data.token`이면 `handleAdmitted(token)` 호출
- `use-vwr-polling.ts` (91-100행): `handleAdmitted()`
  - 94행: `setVwrCookie(token)` - `urr-vwr-token` 쿠키 설정 (max-age=600, SameSite=Strict, Secure)
  - 95행: localStorage 정리
  - 99행: `onAdmitted()` 콜백 실행

#### Step 7: VWR 비활성 시 - 바이패스

- `use-vwr-polling.ts` (187-190행): `status.isActive === false`이면 phase를 "inactive"로 설정하고 `handleAdmitted()` 직접 호출
- `use-vwr-polling.ts` (167-171행): assign 시 404 응답이면 VWR 비활성으로 판단하여 동일하게 바이패스
- `apps/vwr/index.html` (197-203행): 정적 VWR 페이지에서도 404 응답 시 `/events/{eventId}`로 리다이렉트

### 2-5. 큐 대기 (Tier 2)

#### Step 1: 프론트엔드가 /queue/{eventId}로 이동

- `apps/web/src/app/events/[id]/event-detail-client.tsx` (153-155행): VWR에서 admitted 시 `router.push('/queue/{eventId}')`
- `apps/web/src/app/queue/[eventId]/page.tsx` (19-219행): 큐 대기 페이지 컴포넌트

#### Step 2: 프론트엔드가 queue-service check 엔드포인트 호출

- `apps/web/src/app/queue/[eventId]/page.tsx` (77-108행): 마운트 시 `queueApi.check(eventId, vwrPos)` 호출
- `apps/web/src/lib/api-client.ts` (148-152행): `queueApi.check()` - `POST /api/v1/queue/check/{eventId}?vwrPosition=...`
- 27-41행: VWR 토큰에서 position 추출하여 Tier 2 큐 우선순위로 전달 (priority bridging)
- Gateway 라우팅: `application.yml` (41-43행): `/api/v1/queue/**` → queue-service

#### Step 3: queue-service가 Redis에 위치 저장

- `services-spring/queue-service/src/main/java/guru/urr/queueservice/controller/QueueController.java` (29-37행): `POST /api/queue/check/{eventId}` - JWT에서 userId 추출
- `services-spring/queue-service/src/main/java/guru/urr/queueservice/service/QueueService.java` (64-97행): `check()` 메서드
- 67행: `isInQueue()` - Redis ZSET에서 score 조회 (`QueueService.java` 336-339행)
- 74행: `isActiveUser()` - active ZSET에서 만료 시간 기반 확인 (`QueueService.java` 311-315행)
- 82행: `currentUsers >= getThreshold(eventId)` 체크 - 동시 접속 수가 임계값 이상이면 큐에 추가
- 84행: VWR position이 있으면 해당 값을 score로 사용 (VWR 대기 순서 유지)
- 85행: `addToQueue(eventId, userId, score)` - Redis Sorted Set에 추가 (`QueueService.java` 355-358행)
- 293-298행: Redis key 구조 - `{eventId}:queue`, `{eventId}:active` (hash tag로 Redis Cluster slot 친화성 보장)

#### Step 4: 프론트엔드가 폴링으로 위치 업데이트 수신

- `apps/web/src/app/queue/[eventId]/page.tsx` (111행): `useQueuePolling(eventId, joined)` - joined가 true일 때만 폴링 시작
- `apps/web/src/hooks/use-queue-polling.ts` (15-73행): `useQueuePolling()` hook
- 39행: `queueApi.status(eventId)` - `GET /api/v1/queue/status/{eventId}`
- `QueueController.java` (39-46행): `GET /api/queue/status/{eventId}`
- `QueueService.java` (99-137행): `status()` 메서드 - position, peopleAhead, peopleBehind, estimatedWait, entryToken 반환
- `use-queue-polling.ts` (44-46행): 서버 응답의 `nextPoll`로 폴링 간격 동적 조정
- `QueueService.java` (240-247행): `calculateNextPoll()` - 1000명 이내 1초, 5000명 이내 5초, 100000명 이상 60초

#### Step 5: 입장 배치가 주기적으로 실행

- `services-spring/queue-service/src/main/java/guru/urr/queueservice/service/AdmissionWorkerService.java` (47-48행): `@Scheduled(fixedDelayString = "${queue.admission.interval-ms:1000}")` - 1초 간격
- `AdmissionWorkerService.java` (64-119행): `admitUsers()` 메서드
- 51행: `queue:active-events` Set에서 활성 이벤트 목록 조회 (KEYS 커맨드 대신 Set 사용)
- 69-70행: 분산 락 획득 (`admission:lock:{eventId}`, TTL 4초) - 다중 Pod에서 중복 입장 방지
- 80-91행: Lua 스크립트(`admission_control.lua`) 실행 - queue ZSET에서 batch 만큼 pop하여 active ZSET으로 이동
- 96행: `queueService.recordAdmissions(admitted)` - throughput 추적

#### Step 6: 입장 허용 시 - entry token 발급

- `QueueService.java` (206-222행): `buildActiveResponse()` 메서드
- 207행: `generateEntryToken(eventId, userId)` 호출
- `QueueService.java` (224-236행): `generateEntryToken()` - JJWT 라이브러리로 JWT 생성
  - 229-235행: `subject(eventId)`, `claim("uid", userId)`, 만료 시간 = `entryTokenTtlSeconds` (기본 600초)
  - 234행: `signWith(entryTokenKey)` - HMAC-SHA256 서명
- `use-queue-polling.ts` (48-51행): `data.entryToken`이 있으면 `urr-entry-token` 쿠키 설정
- `apps/web/src/app/queue/[eventId]/page.tsx` (94-98행): check 응답에서도 동일하게 entry token을 쿠키에 저장
- `apps/web/src/lib/api-client.ts` (70-77행): 모든 API 요청에 `x-queue-entry-token` 헤더 자동 첨부 (interceptor)

**큐 → 예매 페이지 자동 이동**:
- `apps/web/src/app/queue/[eventId]/page.tsx` (117-127행): `status === "active"` 또는 `queued === false`일 때
  - 121행: `seatLayoutId`가 있으면 `/events/{eventId}/seats`로
  - 123행: 없으면 `/events/{eventId}/book`으로 리다이렉트

### 2-6. 좌석 선택

#### 좌석 배치도 렌더링

- `apps/web/src/app/events/[id]/seats/page.tsx` (71-312행): `SeatsPage` 컴포넌트
- 96-105행: `seatsApi.byEvent(eventId)` → `GET /api/v1/seats/events/{eventId}` 호출
- `apps/web/src/lib/api-client.ts` (174행): `seatsApi.byEvent(eventId)`
- `services-spring/ticket-service/src/main/java/guru/urr/ticketservice/domain/seat/controller/SeatController.java` (38-41행): `GET /api/seats/events/{eventId}` → `catalogReadService.getSeatsByEvent(eventId)`
- 단, 실제 좌석 데이터는 catalog-service의 `EventReadService.getSeatsByEvent()`에서 처리 (`EventReadService.java` 140-173행)
- `seats/page.tsx` (27-57행): `buildSections()` - seats 배열을 섹션 > 열 > 좌석 구조로 변환
- `seats/page.tsx` (169-232행): 섹션별 좌석 그리드 렌더링 (Stage 포함)

#### 좌석 가용성 확인

- `seats/page.tsx` (59-69행): `seatColor()` 함수 - status에 따른 색상 분기
  - `reserved`: 회색 (선택 불가)
  - `locked`: 노란색 (다른 사용자가 선택 중, 선택 불가)
  - `available`: 밝은 회색 (선택 가능)
- `seats/page.tsx` (107-118행): `toggleSeat()` - reserved/locked 상태 좌석은 선택 불가

#### 좌석 잠금 메커니즘 (임시 예약)

- `seats/page.tsx` (120-156행): `handleBook()` - 선택한 좌석으로 `seatsApi.reserve()` 호출
- `apps/web/src/lib/api-client.ts` (175-179행): `seatsApi.reserve()` - `POST /api/v1/seats/reserve` (자동 idempotencyKey 생성)
- `SeatController.java` (43-50행): `POST /api/seats/reserve` → `reservationService.reserveSeats(userId, body)`

**Phase 1: Redis Lua 좌석 락 획득** (DB 락 이전)
- `services-spring/ticket-service/src/main/java/guru/urr/ticketservice/domain/reservation/service/ReservationService.java` (74-89행)
- 77-78행: `seatLockService.acquireLock(eventId, seatId, userId)` 호출
- `services-spring/ticket-service/src/main/java/guru/urr/ticketservice/domain/seat/service/SeatLockService.java` (39-63행): `acquireLock()`
  - 44-49행: Redis Lua 스크립트 실행 (`seatLockAcquireScript`) - 원자적 락 획득 + fencing token 증가
  - 30행: TTL은 `SEAT_LOCK_TTL_SECONDS` (기본 300초 = 5분)
  - 58행: `SeatLockResult(success, fencingToken)` 반환
- 80-88행: 락 실패 시 이미 획득한 락 롤백 후 409 Conflict 응답

**Phase 2: DB 비관적 락 (FOR UPDATE)**
- `ReservationService.java` (92-99행): `SELECT ... FOR UPDATE` - DB 레벨 행 락
- 106-113행: status가 'available'이 아닌 좌석 검증 → 409 Conflict

**Phase 3: 좌석 상태 갱신 + 예약 생성**
- `ReservationService.java` (117-133행): `UPDATE seats SET status = 'locked', version = version + 1, fencing_token = ?` - 낙관적 잠금 (version check)
- 131행: version 불일치 시 동시 수정 감지 → 409 Conflict
- 139-145행: reservations 테이블에 INSERT (`status = 'pending'`, `expires_at = now + 5분`)
- 147-152행: reservation_items 테이블에 좌석별 항목 INSERT

**동시성 처리 (같은 좌석 동시 선택 시)**:
1. Redis Lua 스크립트가 원자적으로 첫 번째 요청만 성공 → 두 번째 요청은 `success=false`
2. DB `FOR UPDATE`로 이중 안전장치
3. `version` 필드를 사용한 낙관적 잠금으로 최종 검증

### 2-7. 결제

#### 결제 시작 (Toss Payments 플로우)

- `apps/web/src/app/payment/[reservationId]/page.tsx` (31-219행): 결제 페이지
- 41-51행: 마운트 시 `reservationsApi.byId(reservationId)` 호출하여 예약 정보 로드
- 53-55행: `useCountdown(info.expires_at)` - 5분 카운트다운 (만료 시 `/my-reservations`로 이동)
- 57-93행: `handlePay()` 함수

**Toss Payments SDK 플로우** (`method === "toss"`):
1. `payment/page.tsx` (65-68행): `paymentsApi.prepare()` → `POST /api/v1/payments/prepare`
   - `services-spring/payment-service/src/main/java/guru/urr/paymentservice/controller/PaymentController.java` (33-40행): `prepare()` 엔드포인트
   - `services-spring/payment-service/src/main/java/guru/urr/paymentservice/service/PaymentService.java` (49-118행): `prepare()` 메서드
   - 71행: `ticketInternalClient.validateReservation(reservationId, userId)` - ticket-service에 예약 유효성 검증
   - 79-81행: 금액 불일치 검증
   - 108행: orderId 생성 (`ORD_{timestamp}_{uuid8}`)
   - 110-115행: payments 테이블에 INSERT (status='pending')
   - 117행: 응답 `{ orderId, amount, clientKey }`

2. `payment/page.tsx` (72-73행): Toss Payments SDK 로드 및 결제 요청
   - `loadTossPayments(clientKey)` → `tossPayments.requestPayment("카드", { amount, orderId, orderName, successUrl, failUrl })`
   - 성공 시 Toss가 `/payment/success?paymentKey=...&orderId=...&amount=...`로 리다이렉트

3. `apps/web/src/app/payment/success/page.tsx`: 결제 성공 콜백 페이지
   - `paymentsApi.confirm()` → `POST /api/v1/payments/confirm`

**간편결제 플로우** (`method !== "toss"`):
- `payment/page.tsx` (82-88행): `paymentsApi.process()` → `POST /api/v1/payments/process`
- `PaymentService.java` (251-341행): `process()` 메서드 - 즉시 confirmed 처리

#### 결제 확인 (confirm)

- `PaymentController.java` (42-49행): `POST /api/payments/confirm`
- `PaymentService.java` (120-173행): `confirm()` 메서드
- 122-127행: `SELECT ... FOR UPDATE` - payments 테이블 행 락
- 134-142행: user_id, amount 검증, 이미 confirmed인지 확인
- 147-149행: reservation 타입이면 ticket-service에서 예약 유효성 재검증
- 153-158행: payments 상태를 `confirmed`로 갱신, `toss_status = 'DONE'` 설정

#### Kafka 이벤트 발행 + 예약 확정

- `PaymentService.java` (343-376행): `completeByType()` 메서드

**동기 경로 (Primary)**:
- 356-366행: `ticketInternalClient.confirmReservation(reservationId, paymentMethod)` 호출
- `services-spring/ticket-service/src/main/java/guru/urr/ticketservice/domain/reservation/service/ReservationService.java` (391-460행): `confirmReservationPayment()`
  - 403-417행: Redis fencing token 검증 (`SeatLockService.verifyForPayment()`) - 좌석 락이 탈취되지 않았는지 확인
  - 420-428행: `UPDATE reservations SET status = 'confirmed', payment_status = 'completed'`
  - 435-447행: seats 상태를 'reserved'로 변경 + Redis 좌석 락 해제 (`SeatLockService.cleanupLock()`)
  - 450-459행: 멤버십 포인트 적립 시도

**비동기 경로 (Secondary - Kafka)**:
- `PaymentService.java` (373-375행): `paymentEventProducer.publish(PaymentConfirmedEvent)` 호출
- `services-spring/payment-service/src/main/java/guru/urr/paymentservice/messaging/PaymentEventProducer.java` (22-30행): `payment-events` 토픽에 발행 (orderId를 key로 사용)
- `services-spring/ticket-service/src/main/java/guru/urr/ticketservice/messaging/PaymentEventConsumer.java` (54-101행): `ticket-service-group`으로 소비
  - 58행: Map → PaymentEvent 타입 변환
  - 62행: 이벤트 키 기반 중복 처리 방지 (`processed_events` 테이블)
  - 103-124행: `handleReservationPayment()` - 동기 경로 실패 시 fallback으로 예약 확정
  - 122-123행: `ReservationConfirmedEvent` 발행 (stats-service 등 후속 소비자용)

### 2-8. 예매 완료

#### 티켓 확인 표시

- `apps/web/src/app/payment/success/page.tsx`: 결제 성공 후 예매 번호 및 상세 정보 표시
- `apps/web/src/app/reservations/[id]/page.tsx`: 예매 상세 조회 페이지
- `apps/web/src/app/my-reservations/page.tsx`: 내 예매 목록 조회

#### Stats 이벤트 발행

- `services-spring/stats-service/src/main/java/guru/urr/statsservice/messaging/StatsEventConsumer.java` (70-113행): `reservation-events` 토픽 소비 (`stats-service-group`)
  - 86-87행: `RESERVATION_CONFIRMED` → `statsWriteService.recordReservationConfirmed(eventId, amount)` 호출
  - 89-90행: `RESERVATION_CANCELLED` → `statsWriteService.recordReservationCancelled(eventId)` 호출
- `StatsEventConsumer.java` (25-68행): `payment-events` 토픽도 별도 소비하여 환불/양도 통계 기록

#### 이메일 알림

- 현재 코드베이스에서는 이메일 발송 로직이 구현되어 있지 않다. Kafka 이벤트 기반으로 notification-service를 추가하여 확장할 수 있는 구조이다.

---

## 3. 데이터 흐름 다이어그램 (텍스트)

### 3-1. 요청 흐름 (Request Flow)

```
User Browser
  |
  v
CloudFront (CDN)
  |-- /vwr/*           --> S3 (정적 VWR 대기 페이지, 캐싱)
  |-- /vwr-api/*       --> API Gateway --> Lambda (VWR API)
  |-- /_next/static/*  --> S3 (Next.js 정적 자산, immutable 캐싱)
  |-- /api/*           --> [Lambda@Edge viewer-request: 토큰 검증]
  |                        --> ALB --> Gateway Service (Spring)
  |                                     |-- /api/v1/auth/**       --> auth-service
  |                                     |-- /api/v1/events/**     --> catalog-service
  |                                     |-- /api/v1/seats/**      --> ticket-service
  |                                     |-- /api/v1/reservations/** --> ticket-service
  |                                     |-- /api/v1/payments/**   --> payment-service
  |                                     |-- /api/v1/queue/**      --> queue-service
  |                                     |-- /api/v1/stats/**      --> stats-service
  |                                     |-- /api/v1/community/**  --> community-service
  |-- /* (default)     --> ALB --> Frontend Pod (Next.js SSR)
```

### 3-2. 이벤트 흐름 (Event Flow via Kafka)

```
payment-service
  |-- PaymentConfirmedEvent --> [payment-events 토픽]
  |                              |--> ticket-service (ticket-service-group)
  |                              |      : 예약 확정, 좌석 상태 변경
  |                              |      : ReservationConfirmedEvent 발행
  |                              |--> stats-service (stats-service-group)
  |                                     : 환불/양도 통계 기록
  |
  |-- PaymentRefundedEvent --> [payment-events 토픽]
                                |--> ticket-service : 예약 취소, 좌석 해제
                                |--> stats-service  : 환불 통계 기록

ticket-service
  |-- ReservationConfirmedEvent --> [reservation-events 토픽]
  |                                   |--> stats-service : 예약 확정 통계
  |-- ReservationCancelledEvent --> [reservation-events 토픽]
  |                                   |--> stats-service : 취소 통계
  |-- TransferCompletedEvent    --> [transfer-events 토픽]
  |                                   |--> stats-service : 양도 통계
  |-- MembershipActivatedEvent  --> [membership-events 토픽]
                                      |--> stats-service : 멤버십 통계
```

### 3-3. 큐 흐름 (Queue Flow)

```
[Tier 1 - VWR (서버리스)]

User --> CloudFront /vwr-api/* --> API Gateway
            |-- POST /vwr/assign/{eventId}
            |     --> Lambda --> DynamoDB (counters: nextPosition++)
            |                --> DynamoDB (positions: requestId 저장)
            |
            |-- GET /vwr/check/{eventId}/{requestId}
            |     --> Lambda --> DynamoDB (positions + counters 조회)
            |                --> position <= servingCounter? --> JWT 발급
            |
            EventBridge (1분) --> Counter Advancer Lambda
                                  --> DynamoDB (counters: servingCounter += 500)

[Tier 2 - Queue (Pod 기반)]

User --> CloudFront /api/* --> ALB --> Gateway --> queue-service
            |-- POST /api/queue/check/{eventId}
            |     --> Redis ZSET 조회/추가
            |     --> currentUsers >= threshold? --> 큐 대기
            |
            |-- GET /api/queue/status/{eventId}
            |     --> Redis ZSET rank 조회 --> position 응답
            |
            AdmissionWorkerService (@Scheduled 1초)
                --> Redis Lua 스크립트: queue ZSET --> active ZSET 이동
                --> 분산 락으로 다중 Pod 충돌 방지
```

---

## 4. 에러 처리 및 복구

### 4-1. VWR Lambda 장애 시

**assign 실패**:
- `apps/web/src/hooks/use-vwr-polling.ts` (165-178행): catch 블록에서 404이면 VWR 비활성으로 판단하여 바이패스 (`phase: "inactive"`, `handleAdmitted()`)
- 기타 에러: `phase: "error"`, 에러 메시지 표시

**check 폴링 실패**:
- `use-vwr-polling.ts` (128-138행): 404이면 localStorage 초기화 후 재할당(`startAssign()`) 시도
- 기타 에러: 5초 후 재시도 (`schedulePoll(requestId, DEFAULT_POLL_SECONDS)`)

**Counter Advancer 실패**:
- `lambda/vwr-counter-advancer/index.js` (46-48행): 개별 사이클 에러 시 로그만 기록하고 다음 사이클 계속 진행
- 84-86행: `ConditionalCheckFailedException` - servingCounter가 이미 nextPosition에 도달한 정상 상황

**Lambda@Edge 장애**:
- `lambda/edge-queue-check/index.js` (30-37행): config.json 로드 실패 시 환경변수 fallback
- `lambda/edge-queue-check/vwr-config.js` (40-56행): S3 설정 로드 실패 시 캐시된 설정 → 번들 설정 → 빈 배열 순 fallback

### 4-2. queue-service 크래시 시

**Redis 연결 실패**:
- `services-spring/queue-service/src/main/java/guru/urr/queueservice/service/QueueService.java` (276-278행): `trackActiveEvent()` - Redis 실패 시 exception 무시 (fire-and-forget)
- `QueueService.java` (367-372행): `touchQueueUser()` - 하트비트 갱신 실패 시 무시
- `AdmissionWorkerService.java` (52-55행): 활성 이벤트 Set 조회 실패 시 `return` (이번 사이클 스킵)
- `AdmissionWorkerService.java` (108-118행): 개별 이벤트 입장 처리 실패 시 catch → warn 로그 → 다음 이벤트 계속
- 분산 락 해제 실패: `AdmissionWorkerService.java` (113-117행) - finally에서 시도하되, 실패 시 락 자동 만료 (4초 TTL)

**Pod 재시작 시**:
- Redis 데이터는 Pod 외부에 있으므로 큐 상태 유지
- `@Scheduled` 배치가 자동으로 재개
- 분산 락(`admission:lock:{eventId}`) TTL이 4초이므로 크래시 시에도 최대 4초 후 다른 Pod가 인수

### 4-3. 결제 실패 처리

**Toss Payments 결제 실패**:
- `apps/web/src/app/payment/[reservationId]/page.tsx` (90-93행): catch → 에러 메시지 표시, `busy = false`로 재시도 허용
- `apps/web/src/app/payment/fail/page.tsx`: Toss가 failUrl로 리다이렉트한 경우 실패 페이지 표시

**결제 확인(confirm) 실패**:
- `PaymentService.java` (129-130행): 결제 레코드 없음 → 404
- `PaymentService.java` (137-138행): 금액 불일치 → 400
- `PaymentService.java` (140-141행): 이미 confirmed → 400 (멱등성 보장)

**동기 확인 실패 시 Kafka fallback**:
- `PaymentService.java` (367-370행): `ticketInternalClient.confirmReservation()` 실패 시 warn 로그만 남기고 계속 진행
- 373-375행: Kafka 이벤트는 항상 발행 → ticket-service의 `PaymentEventConsumer`가 최종 일관성 보장

**예약 만료 처리**:
- `services-spring/ticket-service/src/main/java/guru/urr/ticketservice/scheduling/ReservationCleanupScheduler.java` (37-100행): 30초 간격 스케줄러
- 39-45행: `SELECT ... WHERE status = 'pending' AND expires_at < NOW() FOR UPDATE SKIP LOCKED` - 만료된 예약 검색
- 68-78행: seats 상태를 'available'로 복원 + Redis 좌석 락 해제
- 87-88행: reservations 상태를 'expired'로 변경

### 4-4. 네트워크 타임아웃 처리

**프론트엔드 HTTP 타임아웃**:
- `apps/web/src/lib/api-client.ts` (43행): axios 기본 timeout 15000ms (15초)

**429 Too Many Requests 재시도**:
- `apps/web/src/lib/api-client.ts` (119-127행): 최대 2회 재시도, 지수 백오프 (1초, 2초, 최대 4초)

**401 자동 토큰 갱신**:
- `api-client.ts` (85-116행): 401 응답 시 `/auth/refresh` 호출 → 성공 시 원래 요청 재시도
- 92-97행: 동시 요청 큐잉 - refresh 진행 중인 동안 다른 401 요청은 큐에 대기

### 4-5. Resilience4j Circuit Breaker 패턴

현재 코드베이스에서 Resilience4j 라이브러리는 직접 사용되지 않으나, 유사한 패턴이 구현되어 있다:

- **Gateway 레벨 Rate Limiting**: `services-spring/gateway-service/src/main/java/guru/urr/gatewayservice/filter/RateLimitFilter.java` (24-171행)
  - 경로별 차등 속도 제한: AUTH 60rpm, QUEUE 120rpm, BOOKING 30rpm, GENERAL 3000rpm (`application.yml` 122-125행)
  - 80-99행: Redis Lua 스크립트 기반 sliding window 카운터
  - 100-114행: Redis 장애 시 in-memory ConcurrentHashMap fallback (2배 한도)

- **Entry Token 검증 (Circuit Breaker 역할)**: `services-spring/gateway-service/src/main/java/guru/urr/gatewayservice/filter/VwrEntryTokenFilter.java` (28-142행)
  - 63-72행: CloudFront에서 이미 검증된 경우(`X-CloudFront-Verified` 헤더) 바이패스
  - 108-112행: 토큰 검증 실패 시 403 응답으로 차단

---

## 5. 성능 최적화

### 5-1. CDN 캐싱 전략 (CloudFront Behaviors)

`terraform/modules/cloudfront/main.tf`에서 경로별 캐싱 정책이 세분화되어 있다.

| 경로 패턴 | Origin | 캐싱 정책 | TTL |
|-----------|--------|-----------|-----|
| `/_next/static/*` | S3 | Managed-CachingOptimized | 31536000초 (1년), immutable |
| `/vwr/*` | S3 | vwr_static | 300초 (5분) default, max 3600초 |
| `/api/*` | ALB | api (no-cache) | 0초 (캐싱 없음) |
| `/vwr-api/*` | API GW | api (no-cache) | 0초 |
| `/*` (default) | ALB | frontend_ssr | 0초 default, max 60초 |

- `cloudfront/main.tf` (252-278행): `frontend_ssr` 캐시 정책 - 모든 쿠키 포워딩 (인증 필요), Authorization 헤더 포워딩
- `cloudfront/main.tf` (280-303행): `vwr_static` 캐시 정책 - 쿠키/헤더/쿼리 모두 무시 (순수 정적 콘텐츠)
- `cloudfront/main.tf` (305-331행): `api` 캐시 정책 - TTL 0으로 캐싱 완전 비활성화, 모든 쿠키/쿼리/Authorization 포워딩
- `cloudfront/main.tf` (361-412행): 보안 헤더 정책 - HSTS, X-Content-Type-Options, X-Frame-Options, XSS-Protection, Referrer-Policy
- `cloudfront/main.tf` (182-199행): VWR 정적 페이지용 CloudFront Function - `/vwr/{eventId}` → `/vwr/index.html` 리라이트 (`cloudfront/main.tf` 440-453행)

### 5-2. Redis 캐싱

**queue-service의 Redis 활용**:
- `QueueService.java` (293-307행): Redis key에 hash tag `{eventId}` 사용 → Redis Cluster에서 동일 eventId의 모든 키가 같은 slot에 배치되어 Lua 스크립트의 멀티키 연산 가능
- `QueueService.java` (309-332행): active users는 ZSET의 score를 만료 타임스탬프로 사용 → `ZCOUNT`로 만료되지 않은 활성 사용자 수 즉시 조회

**ticket-service의 Redis 활용**:
- `SeatLockService.java` (39-63행): 좌석 잠금 - Redis Lua 스크립트로 원자적 락 획득/해제
- `SeatLockService.java` (81-99행): 결제 시 fencing token 검증 - 좌석 락이 탈취되지 않았는지 확인

**gateway-service의 Redis 활용**:
- `RateLimitFilter.java` (80-99행): Redis 기반 sliding window rate limiting
- `application.yml` (133-139행): prod 프로필에서 Redis Cluster 모드 설정

### 5-3. Connection Pooling (RDS Proxy)

- Terraform 모듈 `terraform/modules/rds/`에 RDS 구성 정의
- 각 Spring Boot 서비스의 JdbcTemplate이 HikariCP 커넥션 풀 사용 (Spring Boot 기본)
- AWS 배포 시 RDS Proxy를 통해 데이터베이스 연결 풀링 가능

### 5-4. HPA 자동 확장

- `k8s/spring/overlays/prod/hpa.yaml` (1-76행):
  - gateway-service: min 3, max 10, CPU 70%
  - ticket-service: min 3, max 10, CPU 70%
  - queue-service: min 3, max 8, CPU 70%
  - payment-service: min 2, max 6, CPU 70%

### 5-5. Kafka 파티션 전략

- `services-spring/payment-service/src/main/java/guru/urr/paymentservice/messaging/PaymentEventProducer.java` (23행): `kafkaTemplate.send(TOPIC, event.orderId(), event)` - orderId를 파티션 키로 사용하여 동일 주문의 이벤트가 같은 파티션에 순서대로 처리
- `services-spring/ticket-service/src/main/java/guru/urr/ticketservice/messaging/TicketEventProducer.java` (25행): reservationId를 파티션 키로 사용
- Consumer 그룹 분리:
  - `PaymentEventConsumer.java` (54행): `groupId = "ticket-service-group"`
  - `StatsEventConsumer.java` (25행): `groupId = "stats-service-group"`
  - 동일 토픽을 독립적으로 소비하여 서비스 간 결합도 제거

### 5-6. 기타 최적화

**VWR Lambda cold start 최적화**:
- `lambda/vwr-api/index.js` (19행): 단일 Lambda에서 모든 VWR 엔드포인트 처리 → cold start 횟수 최소화
- `lambda/vwr-api/lib/token.js` (9행): 외부 JWT 라이브러리 없이 native crypto 모듈만 사용

**프론트엔드 최적화**:
- `apps/web/src/hooks/use-vwr-polling.ts` (46-51행): 적응형 폴링 간격 - 서버 응답의 `nextPoll` 값에 따라 동적 조정
- `use-queue-polling.ts` (10-13행): 폴링 간격 clamp (min 1초, max 60초)
- `apps/web/src/lib/api-client.ts` (175-179행): idempotencyKey 자동 생성으로 네트워크 재시도 시 중복 예약 방지

**데이터베이스 최적화**:
- `ReservationService.java` (92-99행): `FOR UPDATE`로 비관적 잠금 사용
- `ReservationCleanupScheduler.java` (44행): `FOR UPDATE SKIP LOCKED` - 이미 처리 중인 행 건너뛰기
- `PaymentEventConsumer.java` (217-227행): `processed_events` 테이블로 이벤트 중복 처리 방지

---

## 6. 평가

### 6-1. 잘된 점

**Two-Tier 설계의 장점**

1. **서버리스 유량 제어 + Pod 기반 정밀 순서 관리**: Tier 1(VWR)이 수십만 명의 동시 접속 충격을 흡수하면서 DynamoDB의 원자적 카운터로 공정한 순서를 보장한다. Tier 2(Queue)는 제어된 수의 사용자만 받아 Redis ZSET의 정밀한 순서 관리와 활성 사용자 수 제한을 수행한다.

2. **VWR의 무한 확장성**: Lambda는 리전별 동시 실행 한도(기본 1000, 요청으로 수만까지 증가)까지 자동 확장된다. DynamoDB on-demand는 초당 수만 건의 읽기/쓰기를 처리할 수 있다. S3 + CloudFront의 정적 대기 페이지는 CDN 엣지에서 서빙되어 origin 부하가 사실상 없다.

3. **비용 효율**: VWR은 이벤트 오픈 시에만 비용이 발생하는 서버리스 모델이다. 평소에는 EventBridge 규칙 비활성화 + DynamoDB 최소 비용만 발생한다.

**아키텍처 품질**

4. **명확한 서비스 경계**: catalog(읽기) / ticket(쓰기) / payment / queue / stats / auth / community 서비스가 단일 책임 원칙에 따라 분리되어 있다.

5. **이벤트 기반 최종 일관성**: payment-service → Kafka → ticket-service/stats-service 구조로, 결제 확인과 예약 확정 사이의 일관성을 Kafka 이벤트로 보장한다. `processed_events` 테이블을 활용한 멱등성 처리가 구현되어 있다 (`PaymentEventConsumer.java` 199-239행, `StatsEventConsumer.java` 170-203행).

6. **다층 좌석 동시성 제어**: Redis Lua 락(Phase 1) → DB FOR UPDATE(Phase 2) → 낙관적 잠금 version check(Phase 3) → 결제 시 fencing token 검증(Phase 4)으로 4단계 동시성 보장.

7. **보안 설계**: Lambda@Edge에서 CDN 엣지 레벨 토큰 검증, Gateway에서 JWT 인증 + VWR entry token 검증, 경로별 차등 Rate Limiting, HttpOnly + Secure 쿠키, Refresh Token Rotation + Family 기반 재사용 감지.

### 6-2. 미흡한 점

**사용자 경험 관련**

1. **VWR → Queue 전환 시 이중 대기 경험**: 사용자는 Tier 1(VWR)에서 대기 후 다시 Tier 2(Queue)에서 대기할 수 있다. VWR position을 Queue의 score로 전달하여 우선순위를 연결하고 있으나 (`queue/[eventId]/page.tsx` 79-93행), Queue의 threshold 이내면 바로 입장할 수 있어 사용자 혼란이 있을 수 있다.

2. **좌석 1석 제한**: `ReservationService.java` (35행): `MAX_SEATS_PER_RESERVATION = 1` - 동반자와 함께 예매할 수 없는 제약. 다만 이는 공정성을 위한 의도적 설계일 수 있다.

3. **결제 수단 부분 구현**: `payment/[reservationId]/page.tsx` (82-88행): Toss 외 결제 수단(네이버페이, 카카오페이, 계좌이체)은 `paymentsApi.process()`로 즉시 성공 처리하는 mock 구현이다.

**에러 처리 빈틈**

4. **VWR Counter Advancer 단일 장애점**: EventBridge → Lambda 트리거가 실패하면 대기열이 멈춘다. DLQ(Dead Letter Queue)나 CloudWatch 알람이 코드에 반영되어 있지 않다.

5. **Kafka 이벤트 소비 실패 시 재시도 전략 부재**: `PaymentEventConsumer.java` (98-100행): 예외 발생 시 에러 로그만 남기고 이벤트를 소비 완료한다. DLT(Dead Letter Topic)이나 재시도 정책이 없어 이벤트가 유실될 수 있다.

6. **좌석 락 TTL과 예약 만료 시간 불일치 가능성**: Redis 좌석 락은 5분(`SEAT_LOCK_TTL_SECONDS:300`), 예약 만료도 5분(`expiresAt = now + 5분`)이지만, 네트워크 지연으로 인한 미세한 시간 차이가 race condition을 유발할 수 있다.

**테스트 커버리지**

7. **단위 테스트 부족**: 주요 비즈니스 로직에 대한 테스트 파일이 존재하지만 (`QueueServiceTest.java`, `ReservationServiceTest.java`, `PaymentServiceTest.java`, `AuthServiceTest.java` 등), Lambda 함수에 대한 테스트는 `lambda/edge-queue-check/test/` 디렉토리에만 있고, VWR API Lambda와 Counter Advancer Lambda에는 테스트가 없다.

8. **통합 테스트 부족**: `tests/` 디렉토리에 E2E 테스트 설정이 있으나, Two-Tier 큐 전체 흐름을 커버하는 통합 테스트가 부재하다.

### 6-3. AWS 배포 시 보완 가능한 점

**ElastiCache Cluster Mode for Redis HA**

- 현재 prod 프로필에서 Redis Cluster 설정이 이미 준비되어 있다 (`application.yml` 133-139행)
- `terraform/modules/elasticache/` 모듈 존재
- Cluster 모드 활성화 시 자동 샤딩 + 레플리카로 HA 확보
- hash tag `{eventId}` 기반 키 설계가 이미 되어 있어 Cluster 마이그레이션이 용이 (`QueueService.java` 293-307행)

**RDS Read Replicas for Read-Heavy Queries**

- catalog-service의 이벤트 목록 조회, stats-service의 통계 쿼리는 read-heavy 워크로드
- `terraform/modules/rds/` 모듈에서 read replica 구성 가능
- Spring Boot의 `@Transactional(readOnly = true)` 어노테이션이 이미 적용되어 있어 (`AuthService.java` 86행, 155행 등) 읽기 전용 데이터소스 라우팅이 가능

**CloudFront Regional Edge Caches**

- 현재 CloudFront 배포는 글로벌 엣지를 사용하지만 `price_class` 변수로 제어 (`cloudfront/main.tf` 87행)
- 한국 사용자 대상이면 `PriceClass_200`으로 아시아 태평양 포함 엣지 사용
- Regional Edge Cache는 CloudFront가 자동으로 관리하므로 추가 설정 불필요

**AWS X-Ray for End-to-End Tracing**

- 현재 Zipkin 기반 트레이싱이 설정되어 있다 (`application.yml` 100-105행): `management.zipkin.tracing.endpoint`
- `management.tracing.sampling.probability` 설정 존재 (기본 1.0)
- AWS X-Ray로 전환 시: Lambda → API Gateway → ALB → EKS Pod 전체 경로를 단일 trace로 추적 가능
- Lambda@Edge도 X-Ray 지원하므로 CDN 엣지부터의 전체 레이턴시 가시성 확보

**추가 보완 가능 사항**

- **SQS DLQ**: `services-spring/queue-service/src/main/java/guru/urr/queueservice/config/SqsConfig.java` - 이미 SQS 설정이 있으며, admission 이벤트를 SQS FIFO로 발행 중 (`QueueService.java` 219행). DLQ를 추가하여 실패한 메시지 보존 가능
- **MSK (Managed Kafka)**: `terraform/modules/msk/` 모듈이 존재하여 자체 관리 Kafka 대신 AWS MSK 사용 가능
- **WAF**: `terraform/modules/waf/` 모듈 존재, `cloudfront/main.tf` (88행): `web_acl_id = var.web_acl_arn` - CloudFront에 WAF 연동하여 DDoS/Bot 방어
- **Argo Rollouts**: `k8s/argo-rollouts/` 및 `k8s/spring/overlays/prod/rollouts/` 디렉토리 존재 - Blue-Green 또는 Canary 배포 전략으로 무중단 배포 지원
