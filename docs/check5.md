 최종 결과를 확인합니다.

● Read 2 files (ctrl+o to expand)                                                                                                                                                                                                                    
● 업데이트 완료했습니다. 변경 사항 정리:                                                                                                                                                                                                                                                                                                                                                                                                                                                            
  scripts/start-all.ps1                                                                                                                                                                                                                           
                                                                                                                                                                                                                                                  
  - Step 0 추가: bootRun 전에 7개 환경변수 자동 설정 (JWT_SECRET, INTERNAL_API_TOKEN, QUEUE_ENTRY_TOKEN_SECRET, KAFKA_BOOTSTRAP_SERVERS, ZIPKIN_ENDPOINT, TRACING_SAMPLING_PROBABILITY, TOSS_CLIENT_KEY)                                            - Docker Compose 대기 목록: Kafka(9092), Zipkin(9411) 포트 헬스체크 추가                                                                                                                                                                        
  - Summary 출력: Kafka, Zipkin 포트 정보 표시

  scripts/stop-all.ps1

  - 로그 메시지에 Kafka, Zipkin 포함

  QUICK_START.md

  - Kind 접속 테이블: Zipkin (NodePort 30411) 추가
  - 방법 B 설명: Kafka/Zipkin Docker 포함 명시 + 시크릿 자동 설정 안내 추가
  - 인프라 포트 테이블: Kafka(9092), Zipkin(9411) 추가
  - 검증 섹션: curl http://localhost:9411 추가
  - 트러블슈팅: Kafka/Zipkin 로그 확인 명령어 추가

  이제 start-all.ps1만 실행하면 시크릿 설정 신경 쓸 필요 없이 바로 동작합니다.

✻ Worked for 1m 34s

❯ 우리 msa는 어떻게 되어있고 auth+ membership+ user / tiketing/ admin+ events / waiting/ community/ payment /queue   이구조와 어떻게 다른지 체크해줘                                                                                                                                                                                                                                          
● 현재 프로젝트 구조를 먼저 정확히 파악하겠습니다.                                                                                                                                                                                                                                                                                                                                                                                                                                                  
● Explore(Analyze current MSA structure) Sonnet 4.5                                                                                                                                                                                                 ⎿  Done (47 tool uses · 65.3k tokens · 2m 22s)                                                                                                                                                                                                  
                                                                                                                                                                                                                                                  
● 분석이 완료됐습니다. 두 구조를 비교해드리겠습니다.                                                                                                                                                                                                                                                                                                                                                                                                                                                
  ---                                                                                                                                                                                                                                               현재 MSA 구조 (5개 서비스)                                                                                                                                                                                                                      
                                                                                                                                                                                                                                                    gateway (3001) ─── 라우팅만                                                                                                                                                                                                                       auth-service (3005) ─── 회원가입, 로그인, JWT, OAuth                                                                                                                                                                                              ticket-service (3002) ─── ★ 10개 도메인 집중                                                                                                                                                                                                      payment-service (3003) ─── 결제, 토스 연동                                                                                                                                                                                                        stats-service (3004) ─── 통계 (읽기 전용)                                                                                                                                                                                                       

  ticket-service에 집중된 도메인:
  ┌─────────────┬───────────────────────┬───────────────┐
  │   도메인    │       컨트롤러        │ 엔드포인트 수 │
  ├─────────────┼───────────────────────┼───────────────┤
  │ event       │ EventController       │ 2             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ seat        │ SeatController        │ 4             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ reservation │ ReservationController │ 4             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ queue       │ QueueController       │ 6             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ ticket      │ TicketController      │ 2             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ transfer    │ TransferController    │ 5             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ artist      │ ArtistController      │ 3             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ membership  │ MembershipController  │ 4             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ news        │ NewsController        │ 5             │
  ├─────────────┼───────────────────────┼───────────────┤
  │ admin       │ AdminController       │ 12            │
  └─────────────┴───────────────────────┴───────────────┘
  ---
  제안된 구조 (7개 서비스)

  auth + membership + user ─── 인증 + 멤버십 + 사용자
  ticketing ─── 예매 (좌석, 티켓, 예약)
  admin + events ─── 이벤트 관리 + 어드민
  waiting ─── 대기실/대기열
  community ─── 커뮤니티 (뉴스, 아티스트)
  payment ─── 결제
  queue ─── 메시지 큐/작업 큐

  ---
  핵심 차이점

  1. ticket-service가 사실상 모놀리스

  현재 ticket-service는 10개 도메인을 하나의 서비스에 담고 있습니다. 패키지는 도메인별로 분리했지만 배포 단위는 하나입니다.

  현재:                              제안:
  ┌─────────────────────┐           ┌──────────────────┐
  │   ticket-service    │           │  ticketing        │ ← 예약/좌석/티켓만
  │  ├─ event           │──────────→│  admin + events   │ ← 이벤트/어드민
  │  ├─ seat            │           │  waiting          │ ← 대기열
  │  ├─ reservation     │           │  community        │ ← 뉴스/아티스트
  │  ├─ queue           │           └──────────────────┘
  │  ├─ ticket          │
  │  ├─ transfer        │
  │  ├─ artist          │
  │  ├─ membership      │───────────→ auth+membership+user로 이동
  │  ├─ news            │
  │  └─ admin           │
  └─────────────────────┘

  2. 도메인 배치 차이
  ┌────────────────┬─────────────────┬──────────────────────┬────────────────┐
  │     도메인     │    현재 위치    │      제안 구조       │      차이      │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ user/회원      │ auth-service    │ auth+membership+user │ 동일           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ 로그인/JWT     │ auth-service    │ auth+membership+user │ 동일           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ membership     │ ticket-service  │ auth+membership+user │ 이동           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ reservation    │ ticket-service  │ ticketing            │ 축소           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ seat           │ ticket-service  │ ticketing            │ 축소           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ ticket         │ ticket-service  │ ticketing            │ 축소           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ transfer       │ ticket-service  │ ticketing            │ 축소           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ event          │ ticket-service  │ admin+events         │ 분리           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ admin          │ ticket-service  │ admin+events         │ 분리           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ queue (대기열) │ ticket-service  │ waiting              │ 독립 서비스    │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ news           │ ticket-service  │ community            │ 독립 서비스    │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ artist         │ ticket-service  │ community            │ 독립 서비스    │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ payment        │ payment-service │ payment              │ 동일           │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ stats          │ stats-service   │ (없음?)              │ -              │
  ├────────────────┼─────────────────┼──────────────────────┼────────────────┤
  │ queue (메시지) │ Kafka 인프라    │ queue                │ 별도 서비스화? │
  └────────────────┴─────────────────┴──────────────────────┴────────────────┘
  3. 구체적 차이 분석

  membership → auth 서비스로 이동
  - 현재: ticket-service에서 멤버십 구독/활성화/포인트 관리
  - 제안: auth+user와 함께 묶어서 "사용자 관련" 서비스로 통합
  - 장점: 사용자 프로필과 멤버십 정보를 한 곳에서 조회 가능
  - 단점: 현재 멤버십은 ticket_db의 artist_memberships 테이블을 사용하고, 예약 시 멤버십 등급을 조회하므로 서비스 간 호출이 증가

  event/admin → 별도 서비스
  - 현재: ticket-service 안에서 이벤트 CRUD + 어드민 대시보드
  - 제안: 이벤트 관리를 독립 서비스로 분리
  - 장점: 어드민 트래픽과 유저 트래픽 분리
  - 단점: 예약 생성 시 이벤트 정보/좌석 정보가 필요하므로 ticketing↔admin+events 간 통신 필요

  queue → 독립 서비스 (waiting)
  - 현재: ticket-service 내부에서 Redis 기반 대기열 관리
  - 제안: 독립 서비스로 분리
  - 장점: 대기열은 Redis 중심이라 DB 의존성이 다름, 독립 스케일링 가능
  - 단점: 대기열 통과 후 즉시 예약으로 연결되는 흐름에서 latency 증가

  news/artist → community
  - 현재: ticket-service 내부
  - 제안: 커뮤니티 서비스로 분리
  - 장점: 커뮤니티 기능 확장에 유리 (댓글, 팬 활동 등)
  - 단점: 아티스트 정보는 이벤트/멤버십에서도 참조하므로 데이터 동기화 필요

  4. "queue" 서비스의 의미

  제안 구조에 "waiting"과 "queue"가 둘 다 있습니다:
  - waiting = 유저 대기열 (현재 QueueService가 하는 것)
  - queue = 메시지 큐 인프라? 또는 비동기 작업 큐?

  현재는 Kafka가 메시지 브로커 역할을 인프라로 담당하고 있어서, "queue"를 별도 서비스로 만들 필요성은 낮습니다.

  ---
  정리
  ┌─────────────────────┬────────────────────────────────────┬────────────────────────────────┐
  │        관점         │             현재 (5개)             │           제안 (7개)           │
  ├─────────────────────┼────────────────────────────────────┼────────────────────────────────┤
  │ 서비스 수           │ 5개 (gateway 포함)                 │ 7개 + gateway + stats          │
  ├─────────────────────┼────────────────────────────────────┼────────────────────────────────┤
  │ ticket-service 크기 │ 10개 도메인 (사실상 모놀리스)      │ 3~4개 도메인으로 축소          │
  ├─────────────────────┼────────────────────────────────────┼────────────────────────────────┤
  │ 독립 배포           │ ticket 변경 시 전체 재배포         │ 도메인별 독립 배포 가능        │
  ├─────────────────────┼────────────────────────────────────┼────────────────────────────────┤
  │ 서비스간 통신       │ 단순 (payment↔ticket,              │ 복잡 (7개 서비스 간 다수 호출) │
  │                     │ ticket→auth)                       │                                │
  ├─────────────────────┼────────────────────────────────────┼────────────────────────────────┤
  │ DB 분리             │ 4개 DB                             │ 7개 이상 DB 필요               │
  ├─────────────────────┼────────────────────────────────────┼────────────────────────────────┤
  │ 운영 복잡도         │ 낮음                               │ 높음                           │
  └─────────────────────┴────────────────────────────────────┴────────────────────────────────┘
  현재 구조의 핵심 문제: ticket-service가 너무 큼 → 하지만 패키지를 도메인별로 분리해둬서 향후 서비스 분리 시 경계가 명확합니다.

  제안 구조의 핵심 문제: 서비스 간 데이터 의존성이 높아져서 (이벤트↔예약, 멤버십↔예약, 아티스트↔이벤트) 통신 복잡도와 트랜잭션 관리가 어려워집니다.

  현재 규모에서는 ticket-service를 도메인 패키지로 분리해둔 것이 적절한 균형점이고, 트래픽이 늘어나면 queue(waiting)부터 먼저 분리하는 것이 가장 효과적입니다 (Redis 중심이라 DB 의존성이 낮고, 독립 스케일링 효과가 가장 큼).

✻ Churned for 3m 33s

❯ 아니 좀전에 한 작업이 티켓서비스 분리했던거 아니었어?                                                                                                                                                                                                                                         
● 아닙니다. 이전에 한 작업은 패키지 구조 정리이지, 서비스 분리가 아닙니다.                                                                                                                                                                                                                                                                                                                                                                                                                          
  한 것 vs 안 한 것                                                                                                                                                                                                                               
  
  한 것 (Phase 2 - 패키지 구조 정리):                                                                                                                                                                                                               ticket-service (하나의 서비스, 포트 3002)                                                                                                                                                                                                       
  ├── 변경 전: flat 구조
  │   ├── controller/  ← 컨트롤러 12개 한 폴더에
  │   ├── service/     ← 서비스 15개 한 폴더에
  │   └── dto/         ← DTO 전부 한 폴더에
  │
  ├── 변경 후: 도메인별 패키지 분리
  │   ├── domain/event/controller/ + service/
  │   ├── domain/reservation/controller/ + service/
  │   ├── domain/queue/controller/ + service/
  │   ├── domain/transfer/controller/ + service/
  │   └── ... (10개 도메인)

  배포 단위는 여전히 하나입니다. gradlew bootRun 하면 ticket-service 하나가 3002 포트에 뜨고, 10개 도메인이 전부 그 안에서 동작합니다.

  비유하자면
  ┌────────────────────────┬───────────────────────────────────────────────────────────┐
  │                        │                           설명                            │
  ├────────────────────────┼───────────────────────────────────────────────────────────┤
  │ 패키지 정리 (한 것)    │ 한 집 안에서 방 정리 — 거실에 쌓여있던 물건을 방별로 분류 │
  ├────────────────────────┼───────────────────────────────────────────────────────────┤
  │ 서비스 분리 (안 한 것) │ 한 집을 여러 집으로 쪼개서 각각 독립적으로 운영           │
  └────────────────────────┴───────────────────────────────────────────────────────────┘
  패키지를 도메인별로 나눠둔 덕분에, 나중에 실제로 서비스를 분리할 때 어디를 잘라야 하는지 경계가 명확해진 겁니다. 하지만 현재는 여전히 ticket-service 1개입니다.

❯ 혹시   auth + membership + user ─── 인증 + 멤버십 + 사용자                                                                                                                                                                                      
    ticketing ─── 예매 (좌석, 티켓, 예약)
    admin + events ─── 이벤트 관리 + 어드민                                                                                                                                                                                                           waiting ─── 대기실/대기열                                                                                                                                                                                                                     
    community ─── 커뮤니티 (뉴스, 아티스트)                                                                                                                                                                                                           payment ─── 결제                                                                                                                                                                                                                            
    queue ─── 메시지 큐/작업 큐 이 구조에 맞춰서 전면 수정 가능한가? 이구조에 따라 db 분리하고 묶고                                                                                                                                                                                                                                                                                                                                                                                                 ● 가능은 합니다. 다만 규모가 상당합니다. 현실적으로 뭐가 필요한지 정리해드리겠습니다.                                                                                                                                                                                                                                                                                                                                                                                                               
  작업 규모                                                                                                                                                                                                                                       
  
  서비스 변경 매핑                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  
  현재                          →  목표
  ─────────────────────────────────────────────────────
  auth-service                  →  auth-service (+ membership 추가)
  ticket-service (10개 도메인)   →  4개 서비스로 분해:
    ├─ reservation, seat,          → ticketing-service (신규)
    │  ticket, transfer
    ├─ event, admin                → admin-events-service (신규)
    ├─ queue                       → waiting-service (신규)
    └─ news, artist                → community-service (신규)
  payment-service               →  payment-service (유지)
  stats-service                 →  stats-service (유지)
  gateway-service               →  gateway-service (라우팅 변경)
  (없음)                        →  queue 서비스 (의도 확인 필요)

  DB 분리/병합

  현재 (4개 DB)                →  목표 (7개 DB)
  ──────────────────────────────────────────────
  auth_db (users)              →  auth_db (users + artist_memberships
                                    + membership_point_logs)
  ticket_db (전부)             →  ticketing_db (reservations, reservation_items,
                                    seats, seat_layouts, ticket_types,
                                    ticket_transfers)
                                →  events_db (events, artists 참조?)
                                →  waiting_db (Redis 중심, 보조 테이블만)
                                →  community_db (news, artists)
  payment_db                   →  payment_db (유지)
  stats_db                     →  stats_db (유지)

  핵심 난이도
  ┌────────────────────────┬────────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
  │          항목          │ 난이도 │                                                    이유                                                    │
  ├────────────────────────┼────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
  │ 테이블 간 FK 끊기      │ 높음   │ reservations.event_id → events.id 같은 FK가 서비스 경계를 넘음                                             │
  ├────────────────────────┼────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
  │ 조인 쿼리 분해         │ 높음   │ 현재 JOIN events ON ... 같은 쿼리가 서비스 간 REST 호출로 변환                                             │
  ├────────────────────────┼────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
  │ 트랜잭션 분리          │ 높음   │ 예약 생성 시 이벤트 검증 + 좌석 잠금 + 예약 생성이 하나의 트랜잭션인데, 서비스가 나뉘면 분산 트랜잭션 필요 │
  ├────────────────────────┼────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
  │ 신규 서비스 부트스트랩 │ 중간   │ 4개 Spring Boot 프로젝트 신규 생성 (build.gradle, application.yml, Dockerfile, K8s 매니페스트)             │
  ├────────────────────────┼────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
  │ Kafka 토픽 증가        │ 중간   │ 서비스 간 이벤트 통신 경로가 4~5개 → 10개 이상                                                             │
  ├────────────────────────┼────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
  │ gateway 라우팅         │ 낮음   │ application.yml 수정만                                                                                     │
  └────────────────────────┴────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
  가장 까다로운 부분: 데이터 의존성

  현재 ticket_db 안에서 조인으로 해결하는 것들이 서비스 분리 후 API 호출로 바뀝니다:

  예약 생성 흐름 (현재):
    1. SELECT * FROM events WHERE id = ?          ← 같은 DB
    2. SELECT * FROM seats WHERE event_id = ?     ← 같은 DB
    3. INSERT INTO reservations ...               ← 같은 DB
    → 하나의 트랜잭션

  예약 생성 흐름 (분리 후):
    1. REST → admin-events-service: 이벤트 검증    ← 네트워크
    2. REST → ticketing-service: 좌석 확인          ← 로컬
    3. INSERT INTO reservations ...                ← 로컬
    → 분산 트랜잭션 or Saga 패턴 필요

  솔직한 의견

  할 수 있습니다. 하지만:

  - 신규 Spring Boot 프로젝트 4개 생성
  - DB 스키마 마이그레이션 (테이블 이동 + FK 제거)
  - 서비스 간 REST 클라이언트 8~10개 추가
  - Kafka 토픽 5개 이상 추가
  - Docker/K8s/Terraform 전면 수정
  - 기존 테스트 코드 전부 재작성

  현재 트래픽 규모에서 이 정도 분리가 실제로 필요한지가 핵심입니다. 과도한 분리는 오히려 운영 복잡도만 높이고 latency를 증가시킵니다.

  추천 접근: 전부 한 번에 하기보다 가장 효과가 큰 것부터 단계적으로 분리하는 게 현실적입니다. (예: waiting-service부터 분리 → community → admin+events 순)

  진행할까요? 한다면 전체를 한번에 할지, 단계적으로 할지 어떻게 하시겠습니까?

✻ Worked for 46s

❯ queue 서비스 (의도 확인 필요) 는 보통 따로 안두나? 이게 대기열 부분 아닌가?                                                                                                                                                                                                                                                   
● 맞습니다. 대기열은 보통 독립 서비스로 분리하는 것이 가장 효과적입니다.                                                                                                                                                                                                                                                                                                                                                                                                                            
  이유:                                                                                                                                                                                                                                           
  - Redis 중심이라 PostgreSQL 의존성이 거의 없음
  - 버스트 트래픽이 집중됨 (티켓 오픈 순간)                                                                                                                                                                                                         - 독립 스케일링이 필요한 첫 번째 후보                                                                                                                                                                                                           

  그런데 원래 구조에서 waiting과 queue 둘 다 있었습니다:

  auth+ membership+ user / ticketing / admin+ events / waiting / community / payment / queue
                                                        ↑                              ↑
                                                     이것과                          이것

  이 둘이 같은 대기열을 말하는 건가요? 아니면:
  - waiting = 대기열 (유저가 줄 서는 것)
  - queue = 다른 개념?

  같은 거라면 하나로 합쳐서 6개 서비스가 되는 겁니다.

❯ waiting은 그 vwr말한거긴한데C:\Users\USER\project-ticketing-copy\docs\check.md 이 문서확인해봐                                                                                                                                                  
                                                                                    
● Read 1 file (ctrl+o to expand)                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
● 이 문서를 보니 이해됩니다. 문서에서 설명하는 구조와 비교하면:                                                                                                                                                                                      
  문서의 EKS App Layer 서비스 분리                                                                                                                                                                                                                
                                                                                                                                                                                                                                                  
  문서 402~416줄에서 이렇게 나눕니다:                                                                                                                                                                                                                                                                                                                                                                                                                                                               
  Queue API (경량)        ← 대기열 폴링, Redis ZRANK 조회만
  Booking API (무거움)    ← 좌석 선점 + 결제 처리
  Inventory API           ← 재고 관리, Lua Script 실행

  사용자가 말한 구조와 매핑
  ┌─────────────┬─────────────┬───────────────────────────────────────────────────┐
  │ 사용자 제안 │  문서 개념  │                       역할                        │
  ├─────────────┼─────────────┼───────────────────────────────────────────────────┤
  │ waiting     │ VWR 대기실  │ Lambda@Edge 토큰 검증 + 대기실 페이지 (Edge 레벨) │
  ├─────────────┼─────────────┼───────────────────────────────────────────────────┤
  │ queue       │ Queue API   │ 대기열 폴링 백엔드 (Redis ZRANK/ZCOUNT)           │
  ├─────────────┼─────────────┼───────────────────────────────────────────────────┤
  │ ticketing   │ Booking API │ 좌석 선점 + 예약 확정                             │
  ├─────────────┼─────────────┼───────────────────────────────────────────────────┤
  │ payment     │ 결제 부분   │ 결제 처리                                         │
  └─────────────┴─────────────┴───────────────────────────────────────────────────┘
  즉 waiting과 queue는 다른 계층입니다:
  - waiting = Edge 계층 (CloudFront + Lambda@Edge) - 토큰 없으면 대기실로 리다이렉트
  - queue = App 계층 (Queue API) - Redis ZSET 폴링, 순번 조회, 입장 토큰 발급

  현재 우리 구현과 비교
  ┌──────────────────────────────┬───────────────────────────────────────────┬─────────────────────┐
  │          문서 권장           │                 현재 구현                 │        상태         │
  ├──────────────────────────────┼───────────────────────────────────────────┼─────────────────────┤
  │ Redis ZSET 대기열            │ QueueService - ZADD, ZRANK, ZCOUNT        │ 구현됨              │
  ├──────────────────────────────┼───────────────────────────────────────────┼─────────────────────┤
  │ Admission Control (스케줄러) │ AdmissionWorkerService - 매 1초 배치 입장 │ 구현됨              │
  ├──────────────────────────────┼───────────────────────────────────────────┼─────────────────────┤
  │ TTL 기반 이탈 처리           │ heartbeat + active ZSET으로 TTL 관리      │ 구현됨              │
  ├──────────────────────────────┼───────────────────────────────────────────┼─────────────────────┤
  │ 숏 폴링 + 서버 TTL           │ /api/queue/status 폴링                    │ 구현됨              │
  ├──────────────────────────────┼───────────────────────────────────────────┼─────────────────────┤
  │ Redis Lua 좌석 선점          │ SeatLockService - Redis 기반 분산 락      │ 구현됨 (Lua는 아님) │
  ├──────────────────────────────┼───────────────────────────────────────────┼─────────────────────┤
  │ VWR (Lambda@Edge)            │ 없음                                      │ 미구현              │
  ├──────────────────────────────┼───────────────────────────────────────────┼─────────────────────┤
  │ Queue API 독립 서비스        │ ticket-service 안에 포함                  │ 분리 안 됨          │
  ├──────────────────────────────┼───────────────────────────────────────────┼─────────────────────┤
  │ Inventory API                │ 없음 (별도 재고 관리 없음)                │ 미구현              │
  └──────────────────────────────┴───────────────────────────────────────────┴─────────────────────┘
  백엔드 패턴은 대부분 구현되어 있고, 빠진 건 서비스 분리와 Edge 계층(VWR/Lambda@Edge) 입니다.

  이 문서 기준으로 서비스를 재분리하려면 어떤 범위까지 할지 — 전체 7개 서비스 분리를 할지, 아니면 핵심인 queue(대기열 API) 분리부터 시작할지, 어떻게 하시겠습니까?