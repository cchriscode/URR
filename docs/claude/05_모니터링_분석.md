# URR 모니터링 및 옵저버빌리티 분석

> 분석 기준일: 2026-02-17
> 대상: URR 티켓팅/예약 플랫폼 (Spring Boot 마이크로서비스)

---

## 1. 모니터링 스택 개요

URR 플랫폼은 로컬(Kind) 환경과 프로덕션(AWS EKS) 환경에서 서로 다른 모니터링 스택을 운용한다.

### 1-1. 환경별 스택 비교

| 영역 | Kind (로컬) | Staging / Prod (AWS) |
|------|-------------|---------------------|
| Metrics 수집 | Prometheus v2.51.0 (자체 배포) | kube-prometheus-stack (Helm) |
| Metrics 저장 | Prometheus 로컬 TSDB (7일) | Amazon Managed Prometheus (AMP) (30일) |
| 시각화 | Grafana v10.2.3 (자체 배포) | Amazon Managed Grafana (AMG) |
| 트레이싱 | Zipkin v3 (in-memory) | Zipkin (향후 Elasticsearch) |
| 로깅 수집 | Promtail v2.9.3 (DaemonSet) | CloudWatch Logs (EKS/Lambda/RDS) |
| 로깅 저장 | Loki v2.9.3 (filesystem) | CloudWatch Logs |
| 알림 | Grafana Unified Alerting + Discord | CloudWatch Alarms + SNS + Discord |
| 분산추적 | Micrometer Brave + Zipkin | Micrometer Brave + Zipkin, Lambda X-Ray |

### 1-2. 핵심 소스 파일 목록

- Terraform 모니터링 모듈: `terraform/modules/monitoring/main.tf`
- Kind Prometheus: `k8s/spring/overlays/kind/prometheus.yaml`
- Kind Grafana: `k8s/spring/overlays/kind/grafana.yaml`
- Kind Grafana 대시보드: `k8s/spring/overlays/kind/grafana-dashboards.yaml`
- Kind Grafana 알림: `k8s/spring/overlays/kind/grafana-alerting.yaml`
- Kind Loki: `k8s/spring/overlays/kind/loki.yaml`
- Kind Promtail: `k8s/spring/overlays/kind/promtail.yaml`
- Kind Zipkin: `k8s/spring/overlays/kind/zipkin.yaml`
- Prod 모니터링 Helm values: `k8s/spring/overlays/prod/monitoring-values.yaml`

---

## 2. 메트릭 수집

### 2-1. Spring Boot Actuator

모든 8개 서비스가 동일한 Actuator 설정 패턴을 따른다.

**노출 엔드포인트** (전 서비스 공통):

```yaml
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
```

| 서비스 | 소스 파일 | 라인 |
|--------|-----------|------|
| auth-service | `services-spring/auth-service/src/main/resources/application.yml` | 38-41 |
| catalog-service | `services-spring/catalog-service/src/main/resources/application.yml` | 32-35 |
| gateway-service | `services-spring/gateway-service/src/main/resources/application.yml` | 96-99 |
| payment-service | `services-spring/payment-service/src/main/resources/application.yml` | 44-47 |
| ticket-service | `services-spring/ticket-service/src/main/resources/application.yml` | 58-61 |
| queue-service | `services-spring/queue-service/src/main/resources/application.yml` | 29-31 |
| stats-service | `services-spring/stats-service/src/main/resources/application.yml` | 46-49 |
| community-service | `services-spring/community-service/src/main/resources/application.yml` | 32-34 |

노출되는 3개 엔드포인트:
- `/actuator/health` - 헬스 체크 (liveness/readiness 포함)
- `/actuator/info` - 애플리케이션 정보
- `/actuator/prometheus` - Prometheus 메트릭 스크래핑

**Health 상세 설정** (전 서비스 공통):

```yaml
management:
  endpoint:
    health:
      show-details: always
      show-components: always
      probes:
        enabled: true
  health:
    livenessstate:
      enabled: true
    readinessstate:
      enabled: true
```

서비스별 추가 health indicator:

| 서비스 | 추가 Health Indicator | 소스 파일:라인 |
|--------|----------------------|---------------|
| auth-service | `db: enabled: true` | `application.yml:32-33` |
| catalog-service | `db: enabled: true` | `application.yml:26-27` |
| gateway-service | `redis: enabled: true` | `application.yml:90-91` |
| payment-service | `db: enabled: true` | `application.yml:38-39` |
| ticket-service | `db: enabled: true`, `redis: enabled: true` | `application.yml:50-53` |
| queue-service | `redis: enabled: true` | `application.yml:22-23` |
| stats-service | `db: enabled: true` | `application.yml:40-41` |
| community-service | `db: enabled: true` | `application.yml:24-25` |

**Gradle 의존성** (Prometheus 메트릭 및 트레이싱):

모든 서비스에 다음 3개 의존성이 포함되어 있다:

```groovy
implementation 'io.micrometer:micrometer-registry-prometheus'
implementation 'io.micrometer:micrometer-tracing-bridge-brave'
implementation 'io.zipkin.reporter2:zipkin-reporter-brave'
```

- `services-spring/auth-service/build.gradle:31-33`
- `services-spring/ticket-service/build.gradle:32-34`

`micrometer-registry-prometheus`는 `/actuator/prometheus` 엔드포인트를 활성화하여 다음 메트릭을 자동 노출한다:
- `http_server_requests_seconds_*` (HTTP 요청 히스토그램)
- `jvm_memory_*`, `jvm_gc_*`, `jvm_threads_*` (JVM 메트릭)
- `hikaricp_connections_*` (DB 커넥션 풀)
- `lettuce_command_*` (Redis 명령 레이턴시)
- `kafka_consumer_*`, `kafka_producer_*` (Kafka 메트릭)
- `process_cpu_usage`, `system_cpu_usage` (CPU)
- `disk_free_bytes`, `disk_total_bytes` (디스크)

**커스텀 메트릭**: 현재 코드베이스에 별도의 커스텀 메트릭 정의는 확인되지 않는다. Resilience4j Circuit Breaker 설정이 있는 서비스(catalog, payment, ticket, queue, community)에서는 Resilience4j 내장 메트릭이 자동 노출된다.

### 2-2. Prometheus 수집

#### K8s Pod Annotations (스크래핑 설정)

모든 8개 백엔드 서비스의 Deployment에 동일한 패턴의 Prometheus 스크래핑 annotation이 설정되어 있다:

```yaml
template:
  metadata:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "<서비스포트>"
      prometheus.io/path: "/actuator/prometheus"
```

| 서비스 | 포트 | 소스 파일:라인 |
|--------|------|---------------|
| auth-service | 3005 | `k8s/spring/base/auth-service/deployment.yaml:14-17` |
| gateway-service | 3001 | `k8s/spring/base/gateway-service/deployment.yaml:14-17` |
| ticket-service | 3002 | `k8s/spring/base/ticket-service/deployment.yaml:14-17` |
| payment-service | 3003 | `k8s/spring/base/payment-service/deployment.yaml:14-17` |
| queue-service | 3007 | `k8s/spring/base/queue-service/deployment.yaml:14-17` |
| stats-service | 3004 | `k8s/spring/base/stats-service/deployment.yaml:14-17` |
| catalog-service | 3009 | `k8s/spring/base/catalog-service/deployment.yaml:14-17` |
| community-service | 3008 | `k8s/spring/base/community-service/deployment.yaml:14-17` |

**참고**: frontend Deployment (`k8s/spring/base/frontend/deployment.yaml`)에는 Prometheus annotation이 없다. Next.js 프론트엔드는 메트릭 수집 대상이 아니다.

#### Kind 환경 Prometheus 설정

`k8s/spring/overlays/kind/prometheus.yaml:1-35` (ConfigMap)

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'spring-services'
    metrics_path: '/actuator/prometheus'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - urr-spring
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: "true"
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      - source_labels: [__meta_kubernetes_pod_label_app]
        action: replace
        target_label: service
```

핵심 동작:
1. `urr-spring` 네임스페이스의 모든 Pod을 서비스 디스커버리로 탐색
2. `prometheus.io/scrape: "true"` annotation이 있는 Pod만 필터링
3. annotation의 `path`와 `port` 값으로 스크래핑 엔드포인트 구성
4. Pod의 `app` 레이블을 `service` 라벨로 매핑

Prometheus Deployment:
- 이미지: `prom/prometheus:v2.51.0` (`prometheus.yaml:85`)
- 데이터 보존: 7일 (`--storage.tsdb.retention.time=7d`, `prometheus.yaml:88`)
- 스토리지: PVC `prometheus-pvc` 2Gi (`k8s/spring/overlays/kind/pvc.yaml:53-65`)
- NodePort 접근: `30090` (`prometheus.yaml:138`)
- 리소스: requests 100m/256Mi, limits 500m/512Mi (`prometheus.yaml:98-103`)

#### Amazon Managed Prometheus (AMP) - 프로덕션

`terraform/modules/monitoring/main.tf:5-11`

```hcl
resource "aws_prometheus_workspace" "main" {
  alias = "${var.name_prefix}-amp"
}
```

**IRSA (IAM Roles for Service Accounts)** 설정:
- ServiceAccount: `system:serviceaccount:monitoring:kube-prometheus-stack-prometheus` (`main.tf:101`)
- Remote Write 권한: `aps:RemoteWrite`, `aps:GetSeries`, `aps:GetLabels`, `aps:GetMetricMetadata` (`main.tf:130-135`)
- IAM Role: `${var.name_prefix}-prometheus-amp-irsa` (`main.tf:113`)
- OIDC 조건: EKS 클러스터의 OIDC Provider를 통한 웹 ID 기반 인증 (`main.tf:88-110`)

Output 값:
- `amp_remote_write_url`: `${prometheus_endpoint}api/v1/remote_write` (`outputs.tf:8`)
- `amp_query_url`: AMP 쿼리 엔드포인트 (`outputs.tf:13`)
- `prometheus_irsa_role_arn`: IRSA 역할 ARN (`outputs.tf:28`)

**Prod Helm Values** (`k8s/spring/overlays/prod/monitoring-values.yaml`):

```yaml
prometheus:
  prometheusSpec:
    retention: 30d
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          resources:
            requests:
              storage: 50Gi
    serviceMonitorSelector:
      matchLabels:
        release: kube-prometheus-stack
```

- 데이터 보존: 30일 (Kind 7일 대비 4배 이상)
- 스토리지: gp3 EBS 50Gi
- ServiceMonitor 셀렉터: `release: kube-prometheus-stack` 라벨 매칭

### 2-3. Grafana

#### Kind 환경

`k8s/spring/overlays/kind/grafana.yaml`

- 이미지: `grafana/grafana:10.2.3` (`grafana.yaml:62`)
- 관리자 계정: `admin`/`admin` (`grafana.yaml:68-70`)
- Unified Alerting 활성화: `GF_UNIFIED_ALERTING_ENABLED=true` (`grafana.yaml:73-74`)
- HTTP 포트: 3006 (`grafana.yaml:75-76`)
- NodePort 접근: `30006` (`grafana.yaml:133`)
- 스토리지: PVC `grafana-pvc` 1Gi (`pvc.yaml:28-38`)

**데이터소스 설정** (`grafana.yaml:6-21`):

```yaml
datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus-service:9090
    isDefault: true
  - name: Loki
    type: loki
    access: proxy
    url: http://loki-service:3100
```

#### Amazon Managed Grafana (AMG) - 프로덕션

`terraform/modules/monitoring/main.tf:17-34`

```hcl
resource "aws_grafana_workspace" "main" {
  name                     = "${var.name_prefix}-grafana"
  account_access_type      = "CURRENT_ACCOUNT"
  authentication_providers = ["AWS_SSO"]
  permission_type          = "SERVICE_MANAGED"
  data_sources             = ["PROMETHEUS"]
}
```

핵심 설정:
- 인증: AWS SSO (`main.tf:20`)
- 데이터소스: PROMETHEUS (AMP 연동) (`main.tf:23`)
- 플러그인 관리 활성화: `pluginAdminEnabled: true` (`main.tf:27`)
- IAM Role: Grafana Workspace용 역할 (`main.tf:40-59`)
- AMP 쿼리 권한: `aps:QueryMetrics`, `aps:GetLabels`, `aps:GetSeries`, `aps:GetMetricMetadata` (`main.tf:70-77`)

**Prod Helm Values** (`monitoring-values.yaml:16-29`):

```yaml
grafana:
  persistence:
    enabled: true
    size: 10Gi
  adminPassword: ${GRAFANA_ADMIN_PASSWORD}
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: default
          folder: URR
          type: file
          options:
            path: /var/lib/grafana/dashboards

alertmanager:
  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          resources:
            requests:
              storage: 5Gi
```

#### 대시보드 정의

4개의 사전 프로비저닝 대시보드가 ConfigMap으로 정의되어 있다.

소스: `k8s/spring/overlays/kind/grafana-dashboards.yaml`

**1) Service Overview** (`grafana-dashboards.yaml:9-258`, uid: `urr-service-overview`)

| 패널 ID | 제목 | PromQL | 라인 |
|---------|------|--------|------|
| 1 | Request Rate per Service | `sum(rate(http_server_requests_seconds_count{application=~"$service"}[1m])) by (application)` | 42 |
| 2 | Error Rate per Service (5xx) | `sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m])) / sum(rate(...)) * 100` | 62-68 |
| 3 | Response Time p50 | `histogram_quantile(0.50, sum(rate(http_server_requests_seconds_bucket...)))` | 101 |
| 4 | Response Time p95 | `histogram_quantile(0.95, ...)` | 121 |
| 5 | Response Time p99 | `histogram_quantile(0.99, ...)` | 149 |
| 6 | Active HTTP Connections | `tomcat_connections_current_connections`, `tomcat_threads_busy_threads` | 177-183 |
| 7 | Uptime per Service | `process_uptime_seconds` | 202 |
| 8 | Request Count by Status Code | `sum(increase(http_server_requests_seconds_count[1h])) by (status)` | 231 |
| 9 | Top Endpoints by Request Rate | `topk(15, sum(rate(...[5m])) by (application, uri, method))` | 246 |

Threshold 설정:
- Error Rate: yellow >= 0.1 req/s, red >= 1 req/s (`grafana-dashboards.yaml:78-81`)
- p95 Latency: yellow >= 1s, red >= 3s (`grafana-dashboards.yaml:131-135`)
- p99 Latency: yellow >= 2s, red >= 5s (`grafana-dashboards.yaml:159-163`)

**2) JVM Metrics** (`grafana-dashboards.yaml:260-512`, uid: `urr-jvm-metrics`)

| 패널 ID | 제목 | 주요 메트릭 | 라인 |
|---------|------|-----------|------|
| 1 | Heap Memory Used | `jvm_memory_used_bytes{area="heap"}`, `jvm_memory_max_bytes` | 293-299 |
| 2 | Heap Memory Utilization % | used/max * 100 (gauge) | 324 |
| 3 | Non-Heap Memory Used | `jvm_memory_used_bytes{area="nonheap"}` | 354 |
| 4 | GC Pause Duration | `rate(jvm_gc_pause_seconds_sum[1m])`, count/s | 374-380 |
| 5 | Live Threads | `jvm_threads_live_threads`, daemon, peak | 405-416 |
| 6 | CPU Usage | `process_cpu_usage * 100`, `system_cpu_usage * 100` | 441-447 |
| 7 | Loaded Classes | `jvm_classes_loaded_classes` | 474 |
| 8 | GC Memory Allocated/Promoted | `rate(jvm_gc_memory_allocated_bytes_total[1m])` | 494-499 |

Threshold 설정:
- Heap Utilization: yellow >= 70%, red >= 90% (`grafana-dashboards.yaml:336-340`)

**3) Kafka Metrics** (`grafana-dashboards.yaml:514-718`, uid: `urr-kafka-metrics`)

| 패널 ID | 제목 | 주요 메트릭 | 라인 |
|---------|------|-----------|------|
| 1 | Consumer Lag (Max per Partition) | `kafka_consumer_records_lag_max` | 557 |
| 2 | Consumer Lag (Records) | `kafka_consumer_records_lag` | 585 |
| 3 | Messages Consumed per Second | `rate(kafka_consumer_fetch_manager_records_consumed_total[1m])` | 605 |
| 4 | Messages Produced per Second | `rate(kafka_producer_record_send_total[1m])` | 625 |
| 5 | Consumer Fetch Rate | `kafka_consumer_fetch_manager_fetch_rate` | 645 |
| 6 | Producer Error Rate | `rate(kafka_producer_record_error_total[1m])`, `rate(kafka_producer_record_retry_total[1m])` | 665-671 |
| 7 | Consumer Group Status | `kafka_consumer_coordinator_assigned_partitions` | 697 |

Threshold 설정:
- Consumer Lag Max: yellow >= 100, red >= 1000 (`grafana-dashboards.yaml:568-572`)
- Producer Error: red >= 1 (`grafana-dashboards.yaml:681-684`)

**4) Infrastructure** (`grafana-dashboards.yaml:720-1001`, uid: `urr-infrastructure`)

| 패널 ID | 제목 | 주요 메트릭 | 라인 |
|---------|------|-----------|------|
| 1 | Service Health Status | `up{job="spring-services"}` | 753 |
| 2 | HikariCP Active Connections | `hikaricp_connections_active`, `hikaricp_connections_idle` | 783-789 |
| 3 | HikariCP Pool Utilization | active/max * 100 (gauge) | 808 |
| 4 | HikariCP Connection Acquire Time | `rate(hikaricp_connections_acquire_seconds_sum[1m]) / rate(count[1m])` | 838 |
| 5 | HikariCP Pending Requests | `hikaricp_connections_pending`, `hikaricp_connections_timeout_total` | 866-872 |
| 6 | Redis Command Latency | `rate(lettuce_command_completion_seconds_sum[1m])`, p95 | 899-904 |
| 7 | Redis Command Rate | `rate(lettuce_command_completion_seconds_count[1m])` | 924 |
| 8 | Kafka Broker Availability | `kafka_consumer_connection_count` | 949 |
| 9 | Disk Usage | `disk_free_bytes`, `disk_total_bytes` | 977-982 |

Threshold 설정:
- HikariCP Pool: yellow >= 60%, red >= 85% (`grafana-dashboards.yaml:820-824`)
- Connection Acquire: yellow >= 0.1s, red >= 1s (`grafana-dashboards.yaml:849-853`)
- Pending: yellow >= 1, red >= 5 (`grafana-dashboards.yaml:881-885`)

---

## 3. 분산 트레이싱

### 3-1. Zipkin 설정

#### 의존성 구성

모든 서비스의 `build.gradle`에 Brave 기반 트레이싱 라이브러리가 포함된다:

```groovy
implementation 'io.micrometer:micrometer-tracing-bridge-brave'
implementation 'io.zipkin.reporter2:zipkin-reporter-brave'
```

- `services-spring/auth-service/build.gradle:32-33`
- `services-spring/ticket-service/build.gradle:33-34`

#### application.yml 트레이싱 설정

모든 8개 서비스에 동일한 패턴:

```yaml
management:
  tracing:
    sampling:
      probability: ${TRACING_SAMPLING_PROBABILITY:1.0}
  zipkin:
    tracing:
      endpoint: ${ZIPKIN_ENDPOINT:http://localhost:9411/api/v2/spans}
```

| 서비스 | 소스 파일:라인 |
|--------|---------------|
| auth-service | `application.yml:42-47` |
| catalog-service | `application.yml:36-41` |
| gateway-service | `application.yml:100-105` |
| payment-service | `application.yml:48-53` |
| ticket-service | `application.yml:62-67` |
| queue-service | `application.yml:32-37` |
| stats-service | `application.yml:50-55` |
| community-service | `application.yml:36-40` |

### 3-2. 환경별 ZIPKIN_ENDPOINT 및 샘플링 비율

#### Kind 환경

`k8s/spring/overlays/kind/config.env:14-15`

```
ZIPKIN_ENDPOINT=http://zipkin-spring:9411/api/v2/spans
TRACING_SAMPLING_PROBABILITY=1.0
```

Kind 환경의 각 서비스 patch에서도 ZIPKIN_ENDPOINT를 명시적으로 설정한다:
- `k8s/spring/overlays/kind/patches/auth-service.yaml:31`

#### Staging 환경

`k8s/spring/overlays/staging/patches/services-env.yaml`

모든 서비스에 ZIPKIN_ENDPOINT 설정:
- gateway-service: `services-env.yaml:39`
- auth-service: `services-env.yaml:76`
- ticket-service: `services-env.yaml:111`
- payment-service: `services-env.yaml:142`
- stats-service: `services-env.yaml:170`
- queue-service: `services-env.yaml:199`
- community-service: `services-env.yaml:250`
- catalog-service: `services-env.yaml:285`

Staging에서 `TRACING_SAMPLING_PROBABILITY`는 명시적으로 설정되지 않는다. application.yml의 기본값 `1.0`이 적용된다.

#### Prod 환경

`k8s/spring/overlays/prod/patches/services-env.yaml`

모든 서비스에 명시적 설정:
```yaml
- name: TRACING_SAMPLING_PROBABILITY
  value: "0.1"
```

| 서비스 | 소스 파일:라인 |
|--------|---------------|
| gateway-service | `services-env.yaml:51` |
| auth-service | `services-env.yaml:80` |
| ticket-service | `services-env.yaml:117` |
| payment-service | `services-env.yaml:150` |
| stats-service | `services-env.yaml:181` |
| queue-service | `services-env.yaml:233` |
| community-service | `services-env.yaml:264` |
| catalog-service | `services-env.yaml:301` |

#### 환경별 샘플링 비율 요약

| 환경 | 샘플링 비율 | 근거 |
|------|-----------|------|
| Kind (로컬) | **1.0** (100%) | `config.env:15` |
| Staging | **1.0** (100%, 기본값) | application.yml default, 별도 override 없음 |
| Prod | **0.1** (10%) | `services-env.yaml` 각 서비스별 명시적 설정 |

### 3-3. Trace Context 전파

Spring Boot의 Micrometer Tracing + Brave 브릿지를 사용한다. 로그 패턴에 traceId와 spanId가 포함되어 있어 로그와 트레이스 간 상관 분석이 가능하다:

```yaml
logging:
  pattern:
    level: "%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]"
```

이 패턴은 전 서비스에 공통 적용된다:
- `services-spring/auth-service/src/main/resources/application.yml:49-51`
- `services-spring/gateway-service/src/main/resources/application.yml:107-109`
- `services-spring/ticket-service/src/main/resources/application.yml:69-71`
- (나머지 서비스 동일)

Gateway Service에서 백엔드 서비스로의 요청 시 Brave propagation을 통해 W3C Trace Context 또는 B3 헤더가 자동으로 전파된다.

### 3-4. Zipkin K8s 배포 (Kind)

`k8s/spring/overlays/kind/zipkin.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zipkin-spring
spec:
  replicas: 1
  ...
  containers:
    - name: zipkin
      image: openzipkin/zipkin:3
      ports:
        - containerPort: 9411
      env:
        - name: STORAGE_TYPE
          value: "mem"  # Kind only. Production: "elasticsearch"
```

- 이미지: `openzipkin/zipkin:3` (`zipkin.yaml:17`)
- 스토리지: In-memory (`zipkin.yaml:22`) -- 재시작 시 데이터 소실
- 프로덕션 가이드: Elasticsearch 연동 주석 포함 (`zipkin.yaml:23-27`)
- NodePort 접근: `30411` (`zipkin.yaml:47`)
- 리소스: requests 100m/256Mi, limits 500m/512Mi (`zipkin.yaml:28-34`)

### 3-5. Lambda X-Ray 트레이싱

Lambda Worker에 AWS X-Ray 트레이싱이 활성화되어 있다:

`terraform/modules/lambda-worker/main.tf:106-108`
```hcl
tracing_config {
  mode = var.enable_xray_tracing ? "Active" : "PassThrough"
}
```

Prod 환경에서 `enable_xray_tracing = true`:
`terraform/environments/prod/main.tf:359`

---

## 4. 로깅

### 4-1. 애플리케이션 로그

#### 로그 포맷

모든 Spring Boot 서비스에 trace context가 포함된 로그 레벨 패턴이 설정되어 있다:

```yaml
logging:
  pattern:
    level: "%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]"
```

출력 예시:
```
 INFO [auth-service,6a4b5c3d2e1f0987,a1b2c3d4e5f60789] ...
```

이 패턴은 Logback의 기본 콘솔 출력에 적용된다. 별도의 JSON 구조화 로그 설정이나 `logback-spring.xml` 커스텀 설정 파일은 코드베이스에서 확인되지 않는다.

#### 로그 레벨

application.yml에 명시적인 로그 레벨 설정은 없다. Spring Boot 기본값이 적용된다:
- ROOT: `INFO`
- Spring Framework: `INFO`
- Hibernate SQL: `application.yml`의 `format_sql: true` 설정만 있음 (auth-service `application.yml:13`)

### 4-2. CloudWatch Logs

#### EKS Control Plane 로그

`terraform/modules/eks/main.tf:111`

```hcl
enabled_cluster_log_types = ["api", "audit", "authenticator", "controllerManager", "scheduler"]
```

5종류의 EKS 컨트롤 플레인 로그가 모두 활성화되어 있다.

CloudWatch 로그 그룹:
- 이름: `/aws/eks/${var.name_prefix}/cluster` (`eks/main.tf:446`)
- 보존 기간: `var.log_retention_days` (기본 7일, `eks/variables.tf:125-129`)

#### Lambda Function 로그

`terraform/modules/lambda-worker/main.tf:140-147`

```hcl
resource "aws_cloudwatch_log_group" "lambda" {
  name              = "/aws/lambda/${aws_lambda_function.ticket_worker.function_name}"
  retention_in_days = var.log_retention_days
}
```

- 로그 그룹: `/aws/lambda/${name_prefix}-ticket-worker`
- 보존 기간: `var.log_retention_days` (기본 7일, `lambda-worker/variables.tf:148-152`)

#### RDS PostgreSQL 로그

`terraform/modules/rds/main.tf:90`

```hcl
enabled_cloudwatch_logs_exports = ["postgresql", "upgrade"]
```

내보내지는 로그 유형:
- `postgresql` - 일반 PostgreSQL 로그 (slow query 포함, `log_min_duration_statement=1000ms`, `rds/main.tf:132`)
- `upgrade` - 엔진 업그레이드 관련 로그

추가 DB 파라미터:
- `log_statement = "ddl"` - DDL 문만 기록 (`rds/main.tf:125-128`)
- `log_min_duration_statement = 1000` - 1초 이상 쿼리 기록 (`rds/main.tf:131-133`)

Performance Insights:
- 활성화: `performance_insights_enabled = true` (`rds/main.tf:91`)
- 보존: 7일 (`rds/main.tf:92`)
- Read Replica에도 동일 적용 (`rds/main.tf:277-278`)

Enhanced Monitoring:
- `monitoring_interval`: 변수로 설정 가능 (`rds/main.tf:95`)
- `monitoring_role_arn`: IAM 역할 연동 (`rds/main.tf:96`)

#### ElastiCache Redis 로그

`terraform/modules/elasticache/main.tf:123-135`

```hcl
log_delivery_configuration {
  destination      = var.slow_log_destination      # "/aws/elasticache/redis/slow-log"
  destination_type = "cloudwatch-logs"
  log_format       = "json"
  log_type         = "slow-log"
}

log_delivery_configuration {
  destination      = var.engine_log_destination     # "/aws/elasticache/redis/engine-log"
  destination_type = "cloudwatch-logs"
  log_format       = "json"
  log_type         = "engine-log"
}
```

기본 CloudWatch 로그 그룹 (`elasticache/variables.tf:98-108`):
- Slow log: `/aws/elasticache/redis/slow-log`
- Engine log: `/aws/elasticache/redis/engine-log`
- 형식: JSON

#### CloudWatch 로그 보존 정책 요약

| 로그 소스 | 로그 그룹 패턴 | 보존 기간 | 소스 |
|----------|--------------|----------|------|
| EKS Control Plane | `/aws/eks/${prefix}/cluster` | 7일 | `eks/variables.tf:128` |
| Lambda Worker | `/aws/lambda/${prefix}-ticket-worker` | 7일 | `lambda-worker/variables.tf:152` |
| RDS PostgreSQL | 자동 생성 | AWS 기본값 | `rds/main.tf:90` |
| ElastiCache Slow Log | `/aws/elasticache/redis/slow-log` | AWS 기본값 | `elasticache/variables.tf:101` |
| ElastiCache Engine Log | `/aws/elasticache/redis/engine-log` | AWS 기본값 | `elasticache/variables.tf:107` |

### 4-3. Loki (로컬 Kind 환경)

#### Loki 서버

`k8s/spring/overlays/kind/loki.yaml`

설정 (`loki.yaml:7-42`):
- 인증: 비활성화 (`auth_enabled: false`, `loki.yaml:8`)
- HTTP 포트: 3100 (`loki.yaml:11`)
- 스토리지: 로컬 파일시스템 (`loki.yaml:17-18`)
- Replication Factor: 1 (Kind 전용, 프로덕션은 3 이상 권장 -- `loki.yaml:20`)
- KV Store: inmemory (`loki.yaml:22-23`)
- 스키마: boltdb-shipper + filesystem (`loki.yaml:25-42`)

배포:
- 이미지: `grafana/loki:2.9.3` (`loki.yaml:63`)
- Replica: 1 (Kind 전용, 프로덕션은 loki-distributed Helm chart 권장 -- `loki.yaml:52`)
- 스토리지: PVC `loki-pvc` 2Gi (`pvc.yaml:41-51`)
- 서비스: ClusterIP, port 3100 (`loki.yaml:103-123`)

#### Promtail (로그 수집)

`k8s/spring/overlays/kind/promtail.yaml`

Promtail은 DaemonSet으로 배포되어 모든 노드에서 컨테이너 로그를 수집한다.

설정 (`promtail.yaml:7-31`):
- Loki 엔드포인트: `http://loki-service:3100/loki/api/v1/push` (`promtail.yaml:16`)
- 수집 대상: `urr-spring` 네임스페이스의 모든 Pod (`promtail.yaml:21-24`)
- 라벨: `app` (Pod label), `pod` (Pod name), `namespace` (`promtail.yaml:26-31`)

배포 (`promtail.yaml:33-83`):
- 이미지: `grafana/promtail:2.9.3` (`promtail.yaml:52`)
- 타입: DaemonSet (`promtail.yaml:35`)
- Volume Mounts: `/var/log`, `/var/lib/docker/containers` (읽기 전용)
- ServiceAccount: `promtail` + ClusterRole (pods, nodes, services, endpoints 읽기 권한)
- 리소스: requests 50m/128Mi, limits 200m/256Mi (`promtail.yaml:67-72`)

RBAC (`promtail.yaml:84-117`):
- ServiceAccount: `promtail` (`promtail.yaml:88`)
- ClusterRole: pods, nodes, nodes/proxy, services, endpoints에 get/watch/list (`promtail.yaml:92-103`)
- ClusterRoleBinding: namespace `urr-spring` (`promtail.yaml:113`)

---

## 5. 알림

### 5-1. CloudWatch 알람

#### SQS DLQ 메시지 알람

`terraform/modules/sqs/main.tf:100-118`

```hcl
resource "aws_cloudwatch_metric_alarm" "dlq_messages" {
  alarm_name          = "${var.name_prefix}-ticket-events-dlq-messages"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "ApproximateNumberOfMessagesVisible"
  namespace           = "AWS/SQS"
  period              = 300          # 5분
  statistic           = "Average"
  threshold           = 0            # DLQ에 메시지가 1개라도 있으면 알람
  alarm_description   = "Alert when messages appear in DLQ"
  treat_missing_data  = "notBreaching"
  alarm_actions       = var.sns_topic_arn != "" ? [var.sns_topic_arn] : []
}
```

조건: `enable_cloudwatch_alarms = true` (`sqs/main.tf:101`)
SNS 연동: `var.sns_topic_arn` (`sqs/main.tf:117`)

#### SQS 메시지 처리 지연 알람

`terraform/modules/sqs/main.tf:120-138`

```hcl
resource "aws_cloudwatch_metric_alarm" "queue_age" {
  alarm_name          = "${var.name_prefix}-ticket-events-message-age"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2            # 연속 2회
  metric_name         = "ApproximateAgeOfOldestMessage"
  namespace           = "AWS/SQS"
  period              = 300          # 5분
  statistic           = "Maximum"
  threshold           = 600          # 10분 이상 미처리
  alarm_description   = "Alert when messages are not being processed"
}
```

#### Lambda 에러 알람

`terraform/modules/lambda-worker/main.tf:153-171`

```hcl
resource "aws_cloudwatch_metric_alarm" "lambda_errors" {
  alarm_name          = "${var.name_prefix}-ticket-worker-errors"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "Errors"
  namespace           = "AWS/Lambda"
  period              = 300          # 5분
  statistic           = "Sum"
  threshold           = 5            # 5분간 5회 이상 에러
}
```

#### Lambda 실행 시간 알람

`terraform/modules/lambda-worker/main.tf:173-191`

```hcl
resource "aws_cloudwatch_metric_alarm" "lambda_duration" {
  alarm_name          = "${var.name_prefix}-ticket-worker-duration"
  threshold           = var.lambda_timeout * 1000 * 0.8  # timeout의 80%
  metric_name         = "Duration"
  statistic           = "Average"
}
```

#### Lambda 스로틀 알람

`terraform/modules/lambda-worker/main.tf:193-211`

```hcl
resource "aws_cloudwatch_metric_alarm" "lambda_throttles" {
  alarm_name          = "${var.name_prefix}-ticket-worker-throttles"
  threshold           = 0            # 스로틀 1회라도 발생하면 알람
  metric_name         = "Throttles"
  statistic           = "Sum"
}
```

#### CloudWatch 알람 요약

| 알람 | 메트릭 | 조건 | 기간 | 소스 파일:라인 |
|------|--------|------|------|---------------|
| DLQ 메시지 발생 | `ApproximateNumberOfMessagesVisible` | > 0 | 5분 x 1회 | `sqs/main.tf:100-118` |
| 메시지 처리 지연 | `ApproximateAgeOfOldestMessage` | > 600초 | 5분 x 2회 | `sqs/main.tf:120-138` |
| Lambda 에러 | `Errors` | > 5 | 5분 x 2회 | `lambda-worker/main.tf:153-171` |
| Lambda 실행 시간 | `Duration` | > timeout*80% | 5분 x 2회 | `lambda-worker/main.tf:173-191` |
| Lambda 스로틀 | `Throttles` | > 0 | 5분 x 1회 | `lambda-worker/main.tf:193-211` |

모든 알람은 SNS 토픽으로 알림을 전송한다 (`var.sns_topic_arn`).

#### ElastiCache SNS 알림

`terraform/modules/elasticache/main.tf:138`

```hcl
notification_topic_arn = var.sns_topic_arn
```

ElastiCache 자체 이벤트(failover, 노드 교체 등)가 SNS로 전송된다.

### 5-2. Grafana 알림 (Kind 환경)

#### Alert Rules (대시보드 내장)

`k8s/spring/overlays/kind/grafana-dashboards.yaml` (alerts.json 섹션, 라인 1003-1218)

| 알림 규칙 | 조건 | Duration | Severity | 라인 |
|-----------|------|----------|----------|------|
| High Error Rate | Error rate > 5% | 5분 | Critical | `grafana-dashboards.yaml:1054-1069` |
| Service Down | `up` == 0 | 1분 | Critical | `grafana-dashboards.yaml:1100-1115` |
| High Latency | p95 > 3초 | 5분 | Warning | `grafana-dashboards.yaml:1144-1159` |
| Low Disk Space | 여유 공간 < 10% | 5분 | Warning | `grafana-dashboards.yaml:1190-1205` |

High Error Rate 설정 상세:
```json
"alert": {
  "name": "High Error Rate",
  "message": "Service {{ application }} error rate exceeds 5% for more than 5 minutes.",
  "conditions": [{
    "evaluator": { "type": "gt", "params": [5] }
  }],
  "frequency": "1m",
  "for": "5m"
}
```

#### Grafana Contact Point (Discord)

`k8s/spring/overlays/kind/grafana-alerting.yaml:1-29`

```yaml
contactPoints:
  - orgId: 1
    name: discord-alerts
    receivers:
      - uid: discord
        type: discord
        settings:
          url: ${DISCORD_WEBHOOK_URL}
          message: |
            {{ range .Alerts }}
              **{{ .Labels.alertname }}** - {{ .Status }}
              {{ .Annotations.summary }}
            {{ end }}
policies:
  - orgId: 1
    receiver: discord-alerts
    group_by: ['alertname']
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 4h
```

알림 정책:
- 그룹화: alertname 기준 (`grafana-alerting.yaml:25`)
- 대기: 30초 (`grafana-alerting.yaml:26`)
- 간격: 5분 (`grafana-alerting.yaml:27`)
- 반복: 4시간 (`grafana-alerting.yaml:28`)

### 5-3. Discord 알림 (CI/CD)

`/.github/workflows/reusable-spring-ci-cd.yml:307-357`

CI/CD 파이프라인의 `notify` 잡에서 Discord Webhook을 통해 배포 결과를 알린다:

```yaml
notify:
  name: Notify Discord
  needs: [build-and-push, update-manifests, e2e-gate, load-test]
  if: always()
```

알림 내용 (`reusable-spring-ci-cd.yml:338-356`):
```json
{
  "username": "CI/CD Bot",
  "embeds": [{
    "title": "${EMOJI} ${service-name} deploy ${STATUS_TEXT}",
    "description": "EKS GitOps pipeline result",
    "fields": [
      { "name": "Service", "value": "${service-name}" },
      { "name": "Environment", "value": "${ENVIRONMENT}" },
      { "name": "Image Tag", "value": "${IMAGE_TAG}" },
      { "name": "Logs", "value": "[GitHub Actions](url)" }
    ]
  }]
}
```

성공 시: 녹색 (color: 3066993), "[OK]" 접두사 (`reusable-spring-ci-cd.yml:327-329`)
실패 시: 빨간색 (color: 15158332), "[FAIL]" 접두사 (`reusable-spring-ci-cd.yml:331-333`)

---

## 6. 헬스체크

### 6-1. Spring Boot Health Endpoints

모든 서비스에서 Kubernetes probes를 위한 health endpoint가 활성화되어 있다:

```yaml
management:
  endpoint:
    health:
      probes:
        enabled: true
  health:
    livenessstate:
      enabled: true
    readinessstate:
      enabled: true
```

이로 인해 다음 엔드포인트가 노출된다:
- `/actuator/health` - 전체 상태 (모든 컴포넌트 포함)
- `/actuator/health/liveness` - Kubernetes liveness probe용
- `/actuator/health/readiness` - Kubernetes readiness probe용

`show-details: always`와 `show-components: always` 설정으로 health 응답에 각 컴포넌트(DB, Redis 등)의 상세 상태가 포함된다.

### 6-2. K8s Probes 설정

#### Base Deployment Probes (전 서비스 공통)

모든 8개 Spring 서비스의 base deployment에 동일한 probe 패턴이 적용된다.

**startupProbe**:
```yaml
startupProbe:
  httpGet:
    path: /actuator/health/liveness
    port: <서비스포트>
  failureThreshold: 30
  periodSeconds: 5
```
- 최대 허용 시간: 30 * 5 = **150초** (2분 30초)
- Spring Boot 애플리케이션 초기 기동 시간을 허용

**readinessProbe**:
```yaml
readinessProbe:
  httpGet:
    path: /actuator/health/readiness
    port: <서비스포트>
  periodSeconds: 10
```
- `initialDelaySeconds` 미설정 (startupProbe가 완료된 후 시작)
- 10초 간격으로 readiness 확인

**livenessProbe**:
```yaml
livenessProbe:
  httpGet:
    path: /actuator/health/liveness
    port: <서비스포트>
  periodSeconds: 20
```
- 20초 간격으로 liveness 확인

| 서비스 | 포트 | 소스 파일:라인 (startup/readiness/liveness) |
|--------|------|---------------------------------------------|
| auth-service | 3005 | `base/auth-service/deployment.yaml:43-58` |
| gateway-service | 3001 | `base/gateway-service/deployment.yaml:43-58` |
| ticket-service | 3002 | `base/ticket-service/deployment.yaml:43-58` |
| payment-service | 3003 | `base/payment-service/deployment.yaml:43-58` |
| queue-service | 3007 | `base/queue-service/deployment.yaml:43-58` |
| stats-service | 3004 | `base/stats-service/deployment.yaml:43-58` |
| catalog-service | 3009 | `base/catalog-service/deployment.yaml:43-58` |
| community-service | 3008 | `base/community-service/deployment.yaml:43-58` |

**Frontend Deployment** (`base/frontend/deployment.yaml:47-58`):

Frontend는 Actuator가 아닌 루트 경로를 사용한다:
```yaml
readinessProbe:
  httpGet:
    path: /
    port: 3000
  initialDelaySeconds: 10
  periodSeconds: 5
livenessProbe:
  httpGet:
    path: /
    port: 3000
  initialDelaySeconds: 20
  periodSeconds: 10
```
- startupProbe 미설정
- initialDelaySeconds 사용 (startupProbe 대신)

### 6-3. ALB Health Check

`terraform/modules/alb/main.tf`

#### Gateway Service Target Group

`alb/main.tf:119-150`

```hcl
health_check {
  enabled             = true
  path                = "/health"
  protocol            = "HTTP"
  port                = "traffic-port"
  healthy_threshold   = 2
  unhealthy_threshold = 3
  timeout             = 5
  interval            = 30
  matcher             = "200"
}
```

| 설정 | 값 | 설명 |
|------|-----|------|
| path | `/health` | 헬스체크 경로 |
| healthy_threshold | 2 | 2회 연속 성공시 healthy |
| unhealthy_threshold | 3 | 3회 연속 실패시 unhealthy |
| timeout | 5초 | 응답 타임아웃 |
| interval | 30초 | 체크 간격 |
| matcher | 200 | HTTP 200만 healthy |
| deregistration_delay | 30초 | 등록 해제 지연 (`alb/main.tf:139`) |

#### Frontend Target Group

`alb/main.tf:157-182`

```hcl
health_check {
  path                = "/"
  healthy_threshold   = 2
  unhealthy_threshold = 3
  timeout             = 5
  interval            = 30
  matcher             = "200"
}
```

Gateway와 동일한 파라미터, path만 `/`로 다름.

#### ALB의 unhealthy Pod 감지 흐름

1. ALB는 30초 간격으로 `/health` (gateway) 또는 `/` (frontend)에 HTTP GET 요청
2. 5초 내 HTTP 200 응답 없으면 실패 카운트 증가
3. 3회 연속 실패 시 해당 타겟(Pod IP)을 unhealthy로 마킹
4. unhealthy 타겟에는 트래픽을 라우팅하지 않음
5. 다시 2회 연속 성공하면 healthy로 복귀

### 6-4. Argo Rollouts Analysis

#### AnalysisTemplate 정의

`k8s/spring/overlays/prod/analysis-template.yaml`

```yaml
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: health-check
  namespace: urr-spring
spec:
  args:
    - name: service-name
    - name: port
  metrics:
    - name: health-endpoint
      interval: 10s
      count: 5
      failureLimit: 1
      successCondition: result == 200
      provider:
        web:
          url: "http://{{args.service-name}}.urr-spring.svc.cluster.local:{{args.port}}/health"
          method: GET
          timeoutSeconds: 5
```

검증 로직:
- 10초 간격으로 5회 헬스 체크 실행 (`interval: 10s`, `count: 5`)
- 최대 1회 실패 허용 (`failureLimit: 1`)
- 성공 조건: HTTP 200 응답 (`successCondition: result == 200`)
- 총 소요 시간: 최소 50초 (5회 * 10초)

#### Rollout에서의 사용 (Blue-Green 배포)

4개 핵심 서비스에 Blue-Green 전략 + prePromotionAnalysis가 적용된다:

**gateway-service** (`k8s/spring/overlays/prod/rollouts/gateway-service.yaml:43-57`):
```yaml
strategy:
  blueGreen:
    activeService: gateway-service
    previewService: gateway-service-preview
    autoPromotionEnabled: false
    prePromotionAnalysis:
      templates:
        - templateName: health-check
      args:
        - name: service-name
          value: gateway-service-preview
        - name: port
          value: "3001"
    scaleDownDelaySeconds: 30
```

**ticket-service** (`rollouts/ticket-service.yaml:43-57`):
- preview service: `ticket-service-preview`, port: 3002

**payment-service** (`rollouts/payment-service.yaml:43-57`):
- preview service: `payment-service-preview`, port: 3003

**queue-service** (`rollouts/queue-service.yaml:43-57`):
- preview service: `queue-service-preview`, port: 3007

**Preview Services** (`k8s/spring/overlays/prod/preview-services.yaml`):
4개의 preview Service가 정의되어 있다:
- `gateway-service-preview` (port 3001, `preview-services.yaml:1-11`)
- `ticket-service-preview` (port 3002, `preview-services.yaml:13-23`)
- `payment-service-preview` (port 3003, `preview-services.yaml:25-35`)
- `queue-service-preview` (port 3007, `preview-services.yaml:37-47`)

**배포 판정 흐름**:
1. 새 버전을 preview ReplicaSet으로 배포
2. prePromotionAnalysis가 preview-service 엔드포인트로 health-check 실행
3. 5회 중 4회 이상 성공 (failureLimit=1) -> **promote** (active 교체)
4. 2회 이상 실패 -> **rollback** (preview 삭제)
5. `autoPromotionEnabled: false` -> 수동 프로모션도 가능

---

## 7. 부하 테스트

### 7-1. k6 부하 테스트 워크플로우

`/.github/workflows/load-tests.yml`

#### 트리거 조건

```yaml
on:
  workflow_call:         # 다른 워크플로우에서 호출
  workflow_dispatch:     # 수동 실행
    inputs:
      scenario:
        type: choice
        options:
          # Chaos scenarios
          - service-failure
          - network-latency
          - redis-failure
          # Load scenarios
          - browse-events
          - booking-flow
          - queue-rush
          - mixed-traffic
  schedule:
    - cron: '0 2 * * 1'  # 매주 월요일 02:00 UTC
```

- `load-tests.yml:1-34`

#### 테스트 시나리오 분류

**부하 테스트 시나리오** (`tests/load/scenarios/`):

| 시나리오 | 파일 | 설명 |
|---------|------|------|
| browse-events | `tests/load/scenarios/browse-events.js` | 이벤트 목록 조회 |
| booking-flow | `tests/load/scenarios/booking-flow.js` | 예매 전체 흐름 |
| queue-rush | `tests/load/scenarios/queue-rush.js` | 대기열 동시 접속 |
| mixed-traffic | `tests/load/scenarios/mixed-traffic.js` | 혼합 트래픽 |

**카오스 테스트 시나리오** (`tests/chaos/scenarios/`):

| 시나리오 | 파일 | 설명 |
|---------|------|------|
| service-failure | `tests/chaos/scenarios/service-failure.js` | 서비스 장애 시뮬레이션 |
| network-latency | `tests/chaos/scenarios/network-latency.js` | 네트워크 지연 시뮬레이션 |
| redis-failure | `tests/chaos/scenarios/redis-failure.js` | Redis 장애 시뮬레이션 |

#### 실행 방식

```yaml
- name: Set up k6
  uses: grafana/setup-k6-action@v1

- name: Run k6 load test
  run: k6 run ${{ steps.test-path.outputs.path }} --env BASE_URL=${{ env.BASE_URL }}
```

- `load-tests.yml:48-66`
- 테스트 대상 URL: `https://staging.urr.guru` (기본값, `load-tests.yml:14`)
- 결과 업로드: `results/`, `summary.json` (30일 보존, `load-tests.yml:70-76`)

#### CI/CD 파이프라인 내 부하 테스트

`reusable-spring-ci-cd.yml:298-306`

```yaml
load-test:
  name: Load Test (Baseline)
  needs: [build-and-push, e2e-gate]
  if: needs.build-and-push.outputs.environment == 'staging'
  uses: ./.github/workflows/load-tests.yml
  with:
    scenario: browse-events
    base-url: ${{ vars.STAGING_URL || 'https://staging.urr.guru' }}
```

staging 환경 배포 후 자동으로 `browse-events` 시나리오 실행.

### 7-2. E2E 테스트

`/.github/workflows/e2e-tests.yml`

Playwright 기반 E2E 테스트:
- 브라우저: Chromium (`e2e-tests.yml:45`)
- 대상 URL: staging 환경 (`e2e-tests.yml:9`)
- 트리거: workflow_call, workflow_dispatch, 또는 Auth/Gateway/Frontend CI/CD 완료 후 (`e2e-tests.yml:12-17`)
- 결과 보존: 7일 (`e2e-tests.yml:57`)

### 7-3. 주간 스케줄 테스트

매주 월요일 02:00 UTC에 자동 실행:
```yaml
schedule:
  - cron: '0 2 * * 1'
```
- `load-tests.yml:33-34`
- 기본 시나리오: `service-failure` (chaos test, `load-tests.yml:22`)

---

## 8. 평가

### 잘된 점

1. **일관된 Actuator 설정**: 모든 8개 서비스에 동일한 패턴의 health/prometheus/tracing 설정이 적용되어 있다. 표준화된 구성은 운영 복잡도를 줄인다.

2. **포괄적인 Grafana 대시보드**: 4개의 사전 프로비저닝 대시보드(Service Overview, JVM, Kafka, Infrastructure)가 코드로 관리된다. 서비스 배포 즉시 모니터링이 가능하다.

3. **3-tier Probe 설계**: startupProbe(150초 허용) -> readinessProbe(10초 간격) -> livenessProbe(20초 간격)의 계층적 구조가 Spring Boot의 긴 초기 기동 시간을 적절히 수용한다.

4. **트레이싱 상관관계**: 로그 패턴에 `traceId`와 `spanId`가 포함되어 로그-트레이스 간 상관 분석이 가능하다. 환경별 샘플링 비율(Kind 100%, Prod 10%)도 합리적이다.

5. **Blue-Green 배포 검증**: Argo Rollouts의 prePromotionAnalysis가 새 버전의 health를 자동 검증한 후 프로모션한다. 4개 핵심 서비스(gateway, ticket, payment, queue)에 적용되어 있다.

6. **CloudWatch 알람 다층 구조**: SQS DLQ, 메시지 지연, Lambda 에러/시간/스로틀에 대한 5개 알람이 SNS를 통해 알림을 전송한다.

7. **카오스 테스트**: service-failure, network-latency, redis-failure 시나리오가 정의되어 있어 장애 대응 능력을 사전에 검증할 수 있다.

8. **CI/CD Discord 통합**: 배포 성공/실패 결과가 Discord로 자동 전송되어 팀 수준의 가시성을 확보한다.

### 미흡한 점

1. **구조화 로깅 미적용**: JSON 형식의 구조화 로그가 설정되지 않았다. 현재는 Logback 기본 텍스트 포맷을 사용한다. CloudWatch Logs Insights나 Loki에서 효율적인 쿼리를 하려면 `logback-spring.xml`에 JSON 인코더 설정이 필요하다.

2. **커스텀 비즈니스 메트릭 부재**: 예매 처리량, 결제 성공률, 대기열 대기 시간 등 비즈니스 도메인 특화 메트릭이 없다. Micrometer의 `@Timed`, `Counter`, `Gauge` 등을 활용한 비즈니스 메트릭 추가가 필요하다.

3. **Staging 환경 트레이싱 샘플링 미설정**: Staging에서 `TRACING_SAMPLING_PROBABILITY`가 명시적으로 설정되지 않아 기본값 1.0(100%)이 적용된다. 의도된 것인지 확인이 필요하다. 대량 트래픽 테스트 시 Zipkin에 과도한 부하가 발생할 수 있다.

4. **Zipkin 인메모리 스토리지**: Kind뿐 아니라 프로덕션 참조 코드에도 Elasticsearch 연동이 주석 처리되어 있다. Prod 환경에서 Zipkin을 사용한다면 영구 스토리지 연동이 필수다.

5. **CloudWatch 로그 보존 기간 짧음**: EKS와 Lambda 로그가 7일만 보존된다. 프로덕션 운영에서 인시던트 분석이나 감사 추적을 위해 최소 30일, 규정 준수가 필요하면 90일 이상이 권장된다.

6. **HPA(Horizontal Pod Autoscaler) 메트릭 연동 미흡**: HPA 설정(`k8s/spring/overlays/prod/hpa.yaml`)이 있으나, 커스텀 메트릭 기반 스케일링(예: Kafka consumer lag, 대기열 크기)은 확인되지 않는다.

7. **ALB Health Check 경로 불일치**: ALB Target Group은 `/health`을 사용하지만, K8s probe는 `/actuator/health/liveness`를 사용한다. Gateway Service에 `/health` 엔드포인트가 별도로 존재하는지 확인이 필요하다. 불일치 시 ALB가 Pod을 unhealthy로 판정할 수 있다.

8. **Alertmanager 설정 부재**: Prod Helm values에 Alertmanager 스토리지만 정의되어 있고, 라우팅 규칙이나 수신자(receiver) 설정이 없다. PagerDuty, Slack, Discord 등 실제 알림 채널 연동이 필요하다.

### AWS 배포 시 보완 가능한 점

1. **구조화 로깅 + CloudWatch Logs Insights**: `logback-spring.xml`에 JSON 인코더를 설정하고, CloudWatch Logs Insights로 `traceId` 기반 교차 서비스 로그 검색을 활용할 수 있다. Fluent Bit DaemonSet으로 Pod 로그를 CloudWatch로 직접 전송하는 것도 고려 가능하다.

2. **AWS Distro for OpenTelemetry (ADOT)**: Zipkin 대신 ADOT Collector를 사용하면 AWS X-Ray와 통합되며, AMP로 메트릭도 함께 전송할 수 있다. Lambda의 X-Ray 트레이싱과 EKS 서비스의 트레이싱을 하나의 뷰로 통합할 수 있다.

3. **Container Insights**: EKS 노드와 Pod 수준의 CPU/메모리/네트워크 메트릭을 CloudWatch Container Insights로 수집하면, 현재 애플리케이션 수준 메트릭과 함께 인프라 수준 가시성을 확보할 수 있다.

4. **Composite Alarm**: CloudWatch Composite Alarm을 사용하여 여러 알람 조건을 조합한 지능형 알림이 가능하다. 예: "Lambda 에러 AND SQS DLQ 메시지 존재" 조건으로 false positive를 줄일 수 있다.

5. **CloudWatch 로그 보존 정책 계층화**: Hot(7일, 표준), Warm(30일, Infrequent Access), Cold(365일, Glacier 아카이브) 3단계 보존 전략을 적용할 수 있다.

6. **AMG SLO 대시보드**: Amazon Managed Grafana에 SLI/SLO 대시보드를 추가하여 서비스 수준 목표(예: 가용성 99.9%, p95 지연 < 2초)를 시각화하고 Error Budget을 추적할 수 있다.

7. **Synthetics Canary**: CloudWatch Synthetics로 주기적인 합성 모니터링(로그인 -> 이벤트 조회 -> 예매)을 실행하여 실제 사용자 경험을 프로액티브하게 감시할 수 있다.

8. **비즈니스 메트릭 대시보드**: AMP에 커스텀 비즈니스 메트릭(초당 예매 수, 결제 전환율, 대기열 평균 대기 시간 등)을 수집하고 AMG에 전용 비즈니스 대시보드를 구성할 수 있다.
